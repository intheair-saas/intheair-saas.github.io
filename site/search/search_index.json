{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Repo Description This repo is the Saas Platform's backend, it is meant to serve the data to an other app in the repo named saas_front, and to communicate with the hubspot api. The backend is a rest api, based on the Django framework, it uses celery for its async tasks. The Documentation can be navigated through with the navigation menu. Dependencies Contact","title":"Repo Description"},{"location":"#repo-description","text":"This repo is the Saas Platform's backend, it is meant to serve the data to an other app in the repo named saas_front, and to communicate with the hubspot api. The backend is a rest api, based on the Django framework, it uses celery for its async tasks. The Documentation can be navigated through with the navigation menu.","title":"Repo Description"},{"location":"#dependencies","text":"","title":"Dependencies"},{"location":"#contact","text":"","title":"Contact"},{"location":"Api/Authentication/","text":"Authentication API Note This section is a documentation describing the usage of the Auth endpoints API. Login The login system is based on a JWT systeme, that can be explained in the graph below: To login to the backend server and retrieve the data accessible by the user, a post request should be sent by the user to the /api/login endpoint: Request In order to login to the API you need to send a POST request containing the email and password of the user. POST / HTTP/1.1 Host: <BASE_URL>/api/login/ Header: Content-Type: application/json Body: { email: <EMAIL>, password: <PASS> } <BASE URL> : Being the base url of the backend. <EMAIL> : The users email. <PASS> : The users Password in clear text. Response The response for this request is a json object that contains 2 tokens, a refresh token and an access token. here is an example: {\"refresh\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTY5OTEwMTA0MiwiaWF0IjoxNjk2NTA5MDQyLCJqdGkiOiI5ZjA3NjdjMDNmZmM0ZTI3YmQxODYzMTJiZmI2YjdhZiIsInVzZXJfaWQiOjEsInVzZXJuYW1lIjoiaGFpdGFtIiwidXNlcl90eXBlIjoiQURNSU4ifQ.vzuSpBGo9SxNmHhCpfUkgxZWRM20dvUl5eJQCStxW1M\",\"access\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNjk2NTA5NDAyLCJpYXQiOjE2OTY1MDkwNDIsImp0aSI6ImM0Y2EzMWFhMjc1ZTQxOTQ4ZTk1MDY0YWJmNWQ3NTQ3IiwidXNlcl9pZCI6MSwidXNlcm5hbWUiOiJoYWl0YW0iLCJ1c2VyX3R5cGUiOiJBRE1JTiJ9.t8Dw6dCRVWIJf6yJOTALjCbBfgUhdfUC3Swtm2-KP5g\"} access : The access token is used for the authentication process on each request, it expires every 5 minutes (to be configured in the backend setup)and needs to be refreshed with the refresh token generated with it. refresh : The refresh token is used to refresh the access token and keep the session open. A refresh token gets expired after 30 days Data The access token is JWT encoded and contains some data related to the user connected. if we decode the token we can retrieve this object: { \"token_type\": \"access\", \"exp\": 1696509402, \"iat\": 1696509042, \"jti\": \"c4ca31aa275e41948e95064abf5d7547\", \"user_id\": 1, \"username\": \"haitam\", \"user_type\": \"ADMIN\" } username : username of the user connected. user_type : Type of the user connected (you can check the user types available in user types ) Refresh The access used for authentication gets expired every 5 minutes to maintain a certain level of security. To keep the connection open the user needs to refresh that token using the refresh token generated with it. Request To refresh the access token you need to send a request as follow: POST / HTTP/1.1 Host: <BASE_URL>/api/token/refresh/ Header: Content-Type: application/json Body: { refresh: <REFRESH TOKEN> } <BASE URL> : Being the base url of the backend. <REFRESH TOKEN> : The refresh token generated earlier. Response The response for the refresh token is as follow : {\"refresh\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTY5OTEwMTA0MiwiaWF0IjoxNjk2NTA5MDQyLCJqdGkiOiI5ZjA3NjdjMDNmZmM0ZTI3YmQxODYzMTJiZmI2YjdhZiIsInVzZXJfaWQiOjEsInVzZXJuYW1lIjoiaGFpdGFtIiwidXNlcl90eXBlIjoiQURNSU4ifQ.vzuSpBGo9SxNmHhCpfUkgxZWRM20dvUl5eJQCStxW1M\",\"access\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNjk2NTA5NDAyLCJpYXQiOjE2OTY1MDkwNDIsImp0aSI6ImM0Y2EzMWFhMjc1ZTQxOTQ4ZTk1MDY0YWJmNWQ3NTQ3IiwidXNlcl9pZCI6MSwidXNlcm5hbWUiOiJoYWl0YW0iLCJ1c2VyX3R5cGUiOiJBRE1JTiJ9.t8Dw6dCRVWIJf6yJOTALjCbBfgUhdfUC3Swtm2-KP5g\"} access : New generated access token. refresh : New refresh token. Important After a refresh token is used, it is being blacklisted , therefore impossible to use a second time to refresh the access token. You will need to use the newly generated refresh token every time you refresh the access token.","title":"Authentication API"},{"location":"Api/Authentication/#authentication-api","text":"Note This section is a documentation describing the usage of the Auth endpoints API.","title":"Authentication API"},{"location":"Api/Authentication/#login","text":"The login system is based on a JWT systeme, that can be explained in the graph below: To login to the backend server and retrieve the data accessible by the user, a post request should be sent by the user to the /api/login endpoint:","title":"Login"},{"location":"Api/Authentication/#request","text":"In order to login to the API you need to send a POST request containing the email and password of the user. POST / HTTP/1.1 Host: <BASE_URL>/api/login/ Header: Content-Type: application/json Body: { email: <EMAIL>, password: <PASS> } <BASE URL> : Being the base url of the backend. <EMAIL> : The users email. <PASS> : The users Password in clear text.","title":"Request"},{"location":"Api/Authentication/#response","text":"The response for this request is a json object that contains 2 tokens, a refresh token and an access token. here is an example: {\"refresh\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTY5OTEwMTA0MiwiaWF0IjoxNjk2NTA5MDQyLCJqdGkiOiI5ZjA3NjdjMDNmZmM0ZTI3YmQxODYzMTJiZmI2YjdhZiIsInVzZXJfaWQiOjEsInVzZXJuYW1lIjoiaGFpdGFtIiwidXNlcl90eXBlIjoiQURNSU4ifQ.vzuSpBGo9SxNmHhCpfUkgxZWRM20dvUl5eJQCStxW1M\",\"access\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNjk2NTA5NDAyLCJpYXQiOjE2OTY1MDkwNDIsImp0aSI6ImM0Y2EzMWFhMjc1ZTQxOTQ4ZTk1MDY0YWJmNWQ3NTQ3IiwidXNlcl9pZCI6MSwidXNlcm5hbWUiOiJoYWl0YW0iLCJ1c2VyX3R5cGUiOiJBRE1JTiJ9.t8Dw6dCRVWIJf6yJOTALjCbBfgUhdfUC3Swtm2-KP5g\"} access : The access token is used for the authentication process on each request, it expires every 5 minutes (to be configured in the backend setup)and needs to be refreshed with the refresh token generated with it. refresh : The refresh token is used to refresh the access token and keep the session open. A refresh token gets expired after 30 days","title":"Response"},{"location":"Api/Authentication/#data","text":"The access token is JWT encoded and contains some data related to the user connected. if we decode the token we can retrieve this object: { \"token_type\": \"access\", \"exp\": 1696509402, \"iat\": 1696509042, \"jti\": \"c4ca31aa275e41948e95064abf5d7547\", \"user_id\": 1, \"username\": \"haitam\", \"user_type\": \"ADMIN\" } username : username of the user connected. user_type : Type of the user connected (you can check the user types available in user types )","title":"Data"},{"location":"Api/Authentication/#refresh","text":"The access used for authentication gets expired every 5 minutes to maintain a certain level of security. To keep the connection open the user needs to refresh that token using the refresh token generated with it.","title":"Refresh"},{"location":"Api/Authentication/#request_1","text":"To refresh the access token you need to send a request as follow: POST / HTTP/1.1 Host: <BASE_URL>/api/token/refresh/ Header: Content-Type: application/json Body: { refresh: <REFRESH TOKEN> } <BASE URL> : Being the base url of the backend. <REFRESH TOKEN> : The refresh token generated earlier.","title":"Request"},{"location":"Api/Authentication/#response_1","text":"The response for the refresh token is as follow : {\"refresh\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6MTY5OTEwMTA0MiwiaWF0IjoxNjk2NTA5MDQyLCJqdGkiOiI5ZjA3NjdjMDNmZmM0ZTI3YmQxODYzMTJiZmI2YjdhZiIsInVzZXJfaWQiOjEsInVzZXJuYW1lIjoiaGFpdGFtIiwidXNlcl90eXBlIjoiQURNSU4ifQ.vzuSpBGo9SxNmHhCpfUkgxZWRM20dvUl5eJQCStxW1M\",\"access\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNjk2NTA5NDAyLCJpYXQiOjE2OTY1MDkwNDIsImp0aSI6ImM0Y2EzMWFhMjc1ZTQxOTQ4ZTk1MDY0YWJmNWQ3NTQ3IiwidXNlcl9pZCI6MSwidXNlcm5hbWUiOiJoYWl0YW0iLCJ1c2VyX3R5cGUiOiJBRE1JTiJ9.t8Dw6dCRVWIJf6yJOTALjCbBfgUhdfUC3Swtm2-KP5g\"} access : New generated access token. refresh : New refresh token. Important After a refresh token is used, it is being blacklisted , therefore impossible to use a second time to refresh the access token. You will need to use the newly generated refresh token every time you refresh the access token.","title":"Response"},{"location":"Api/Company/","text":"Company Endpoints This page regroups a set of endpoints to interact with the companies related data. Retrieve data Single company data : company/<id> To retrieve a company data you can request the api endpoint /api/company/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/company/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The company's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the sector's data: { \"id\":27, \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":\"http://127.0.0.1:8000/media/logos/legal_name/logo.png\", \"activity_sector\":\"sector 1\" } All Companies Data : company/ To retrieve the list of all the companies and their data at once you can request the api endpoint /api/company/ : GET / HTTP/1.1 Host: <BASE_URL>/api/company/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains companies data (The list of all companies): [ { \"id\":27, \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":\"http://127.0.0.1:8000/media/logos/legal_name/logo.png\", \"activity_sector\":\"sector 1\" }, { \"id\":25, \"N_SIRET\":12345, \"commercial_name\":\"com_name_2\", \"legal_name\":\"legal_name_2\", \"address\":\"address_2\", \"telephone_number\":\"0617895899\", \"hubspot_company_id\":\"HUBSPOT_ID_2\", \"company_logo\":\"http://127.0.0.1:8000/media/logos/legal_name_2/logo.png\", \"activity_sector\":\"sector 2\" }, ... ... ] Delete Company Important Only ADMIN users can delete companies. To delete a company data you can request the api endpoint /api/company/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/company/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The company's id you want to delete. <ACCESS TOKEN> : The connected user's access token. Create company Important Only ADMIN or AG_DATA users can create companies with this API. To create a company data you can request the api endpoint /api/company/ : NEEDS TO BE EDITED POST / HTTP/1.1 Host: <BASE_URL>/api/company/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":[PNG/JPG Object], \"activity_sector\":\"sector 1\" } <ACCESS TOKEN> : The connected user's access token. Update company Important Only ADMIN or AG_DATA users can update companies with this API. To update a company's data you can request the api endpoint /api/company/<id> : PUT / HTTP/1.1 Host: <BASE_URL>/api/company/<id>/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":[PNG/JPG Object], \"activity_sector\":\"sector 1\" } <ACCESS TOKEN> : The connected user's access token. <id> : The company's id you want to update.","title":"Company Endpoints"},{"location":"Api/Company/#company-endpoints","text":"This page regroups a set of endpoints to interact with the companies related data.","title":"Company Endpoints"},{"location":"Api/Company/#retrieve-data","text":"","title":"Retrieve data"},{"location":"Api/Company/#single-company-data-companyid","text":"To retrieve a company data you can request the api endpoint /api/company/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/company/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The company's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the sector's data: { \"id\":27, \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":\"http://127.0.0.1:8000/media/logos/legal_name/logo.png\", \"activity_sector\":\"sector 1\" }","title":"Single company data : company/&lt;id&gt;"},{"location":"Api/Company/#all-companies-data-company","text":"To retrieve the list of all the companies and their data at once you can request the api endpoint /api/company/ : GET / HTTP/1.1 Host: <BASE_URL>/api/company/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains companies data (The list of all companies): [ { \"id\":27, \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":\"http://127.0.0.1:8000/media/logos/legal_name/logo.png\", \"activity_sector\":\"sector 1\" }, { \"id\":25, \"N_SIRET\":12345, \"commercial_name\":\"com_name_2\", \"legal_name\":\"legal_name_2\", \"address\":\"address_2\", \"telephone_number\":\"0617895899\", \"hubspot_company_id\":\"HUBSPOT_ID_2\", \"company_logo\":\"http://127.0.0.1:8000/media/logos/legal_name_2/logo.png\", \"activity_sector\":\"sector 2\" }, ... ... ]","title":"All Companies Data : company/"},{"location":"Api/Company/#delete-company","text":"Important Only ADMIN users can delete companies. To delete a company data you can request the api endpoint /api/company/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/company/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The company's id you want to delete. <ACCESS TOKEN> : The connected user's access token.","title":"Delete Company"},{"location":"Api/Company/#create-company","text":"Important Only ADMIN or AG_DATA users can create companies with this API. To create a company data you can request the api endpoint /api/company/ : NEEDS TO BE EDITED POST / HTTP/1.1 Host: <BASE_URL>/api/company/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":[PNG/JPG Object], \"activity_sector\":\"sector 1\" } <ACCESS TOKEN> : The connected user's access token.","title":"Create company"},{"location":"Api/Company/#update-company","text":"Important Only ADMIN or AG_DATA users can update companies with this API. To update a company's data you can request the api endpoint /api/company/<id> : PUT / HTTP/1.1 Host: <BASE_URL>/api/company/<id>/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"N_SIRET\":12345, \"commercial_name\":\"com_name\", \"legal_name\":\"legal_name\", \"address\":\"address\", \"telephone_number\":\"0612345789\", \"hubspot_company_id\":\"HUBSPOT_ID\", \"company_logo\":[PNG/JPG Object], \"activity_sector\":\"sector 1\" } <ACCESS TOKEN> : The connected user's access token. <id> : The company's id you want to update.","title":"Update company"},{"location":"Api/Permissions/","text":"","title":"Permissions"},{"location":"Api/Project/","text":"Project Endpoints This page regroups a set of endpoints to interact with the projects related data. Retrieve data Single project data : project/<id> To retrieve a project data you can request the api endpoint /api/project/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/project/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the project's data: { \"id\": 1, \"project_type_label\": \"projectType 1\", \"user_username\": \"g_b_m\", \"delimitation_field\": { \"type\": \"FeatureCollection\", \"features\": [ { \"id\": 1, \"type\": \"Feature\", \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -0.628928171672778, 43.44337246385466, 0 ], ..., [ -0.630138420045127, 43.44103583242925, 0 ], [ -0.628928171672778, 43.44337246385466, 0 ] ] ] ] }, \"properties\": { \"project\": 1 } } ] }, \"name\": \"project_test\", \"description\": \"gregreergerw\", \"hubspot_proj_id\": \"johfodsfhof\", \"last_edit\": \"2024-01-26T14:56:29.900846Z\", \"area_file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/Arthez.kml?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T231454Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=3e933fb285a6d71a80a78b838ed04c908483e2a543ee1b245606d6529fc87eb54cc34f540d61ba9005958b848d0319b17f06226476c2ef64edf63e8c234b1d6f3338d2209e28224031cf7dcf5f0bad127bce3c669ec6848bb4e4681235ffa0ce0abf83ac45304723e31717fc634cc122b7d8e3eb3cd57604cb5804a9f320906843f43fc3f6e8f1c1670178697ab75705137ca8324f5743f2759f770f0310187b1150032ef4ad747b8fd8a1fe1b9591002b6fac28bac67e5a547b035994dfe12a1cd92bf64fd7229557e0c933d0318a389fb2fe3bfdc8cb885d60e2fa1de786a701a129c8131342178e1830c950324013e8e194da70234ac25f733c3d6a06d7ba\", \"area\": 169751.05240838812, \"lat\": -0.6289281716727779, \"long\": 43.44337246385466, \"is_archived\": false, \"proj_type\": 1, \"user\": 2 } project_type_label : label of the project type the project is associated with. delimitation_field : A geojson object generated from the kml file used to create the project, it is the delimitation polygone of the project on the map. area_file : Link to the kml file of the project, it is the file that contains the delimitation shape of the project on the map. proj_type : id of the project type the project is associated to. user : id of the user the project is associated to All Projects Data : project/ To retrieve the list of all the projects and their data at once you can request the api endpoint /api/project/ : GET / HTTP/1.1 Host: <BASE_URL>/api/project/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains projects data (The list of all projects): [ { \"id\": 1, \"project_type_label\": \"projectType 1\", \"user_username\": \"g_b_m\", \"delimitation_field\": { \"type\": \"FeatureCollection\", \"features\": [ { \"id\": 1, \"type\": \"Feature\", \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -0.628928171672778, 43.44337246385466, 0 ], ..., [ -0.630138420045127, 43.44103583242925, 0 ], [ -0.628928171672778, 43.44337246385466, 0 ] ] ] ] }, \"properties\": { \"project\": 1 } } ] }, \"name\": \"project_test\", \"description\": \"gregreergerw\", \"hubspot_proj_id\": \"johfodsfhof\", \"last_edit\": \"2024-01-26T14:56:29.900846Z\", \"area_file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/Arthez.kml?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T231454Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=3e933fb285a6d71a80a78b838ed04c908483e2a543ee1b245606d6529fc87eb54cc34f540d61ba9005958b848d0319b17f06226476c2ef64edf63e8c234b1d6f3338d2209e28224031cf7dcf5f0bad127bce3c669ec6848bb4e4681235ffa0ce0abf83ac45304723e31717fc634cc122b7d8e3eb3cd57604cb5804a9f320906843f43fc3f6e8f1c1670178697ab75705137ca8324f5743f2759f770f0310187b1150032ef4ad747b8fd8a1fe1b9591002b6fac28bac67e5a547b035994dfe12a1cd92bf64fd7229557e0c933d0318a389fb2fe3bfdc8cb885d60e2fa1de786a701a129c8131342178e1830c950324013e8e194da70234ac25f733c3d6a06d7ba\", \"area\": 169751.05240838812, \"lat\": -0.6289281716727779, \"long\": 43.44337246385466, \"is_archived\": false, \"proj_type\": 1, \"user\": 2 }, { \"id\": 1, \"project_type_label\": \"projectType 1\", \"user_username\": \"g_b_m\", \"delimitation_field\": { \"type\": \"FeatureCollection\", \"features\": [ { \"id\": 1, \"type\": \"Feature\", \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -0.628928171672778, 43.44337246385466, 0 ], ..., [ -0.630138420045127, 43.44103583242925, 0 ], [ -0.628928171672778, 43.44337246385466, 0 ] ] ] ] }, \"properties\": { \"project\": 1 } } ] }, \"name\": \"project_test\", \"description\": \"gregreergerw\", \"hubspot_proj_id\": \"johfodsfhof\", \"last_edit\": \"2024-01-26T14:56:29.900846Z\", \"area_file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/Arthez.kml?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T231454Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=3e933fb285a6d71a80a78b838ed04c908483e2a543ee1b245606d6529fc87eb54cc34f540d61ba9005958b848d0319b17f06226476c2ef64edf63e8c234b1d6f3338d2209e28224031cf7dcf5f0bad127bce3c669ec6848bb4e4681235ffa0ce0abf83ac45304723e31717fc634cc122b7d8e3eb3cd57604cb5804a9f320906843f43fc3f6e8f1c1670178697ab75705137ca8324f5743f2759f770f0310187b1150032ef4ad747b8fd8a1fe1b9591002b6fac28bac67e5a547b035994dfe12a1cd92bf64fd7229557e0c933d0318a389fb2fe3bfdc8cb885d60e2fa1de786a701a129c8131342178e1830c950324013e8e194da70234ac25f733c3d6a06d7ba\", \"area\": 169751.05240838812, \"lat\": -0.6289281716727779, \"long\": 43.44337246385466, \"is_archived\": false, \"proj_type\": 1, \"user\": 2 } ... ... ] Delete project Important Only ADMIN users can delete projects. To delete a project data you can request the api endpoint /api/project/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/project/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project's id you want to delete. <ACCESS TOKEN> : The connected user's access token. Create project Important Only ADMIN or AG_DATA users can create projects with this API. To create a project data you can request the api endpoint /api/project/ : NEEDS TO BE EDITED POST / HTTP/1.1 Host: <BASE_URL>/api/project/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"name\":\"project_2\", \"description\":\"Geographic Data with points\", \"hubspot_proj_id\":\"ffwefw\", \"area_file\":[KML FILE], \"proj_type\":1, \"user\":2 } <ACCESS TOKEN> : The connected user's access token. proj_type : id of the project type the project is associated to. user : id of the user the project is associated to Update project Important Only ADMIN or AG_DATA users can update projects with this API. To update a project's data you can request the api endpoint /api/project/ : NEEDS TO BE EDITED PUT / HTTP/1.1 Host: <BASE_URL>/api/project/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"name\":\"project_2\", \"description\":\"Geographic Data with points\", \"hubspot_proj_id\":\"ffwefw\", \"area_file\":[KML FILE], \"proj_type\":1, \"user\":2 } <ACCESS TOKEN> : The connected user's access token. <id> : The project's id you want to update.","title":"Project Endpoints"},{"location":"Api/Project/#project-endpoints","text":"This page regroups a set of endpoints to interact with the projects related data.","title":"Project Endpoints"},{"location":"Api/Project/#retrieve-data","text":"","title":"Retrieve data"},{"location":"Api/Project/#single-project-data-projectid","text":"To retrieve a project data you can request the api endpoint /api/project/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/project/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the project's data: { \"id\": 1, \"project_type_label\": \"projectType 1\", \"user_username\": \"g_b_m\", \"delimitation_field\": { \"type\": \"FeatureCollection\", \"features\": [ { \"id\": 1, \"type\": \"Feature\", \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -0.628928171672778, 43.44337246385466, 0 ], ..., [ -0.630138420045127, 43.44103583242925, 0 ], [ -0.628928171672778, 43.44337246385466, 0 ] ] ] ] }, \"properties\": { \"project\": 1 } } ] }, \"name\": \"project_test\", \"description\": \"gregreergerw\", \"hubspot_proj_id\": \"johfodsfhof\", \"last_edit\": \"2024-01-26T14:56:29.900846Z\", \"area_file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/Arthez.kml?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T231454Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=3e933fb285a6d71a80a78b838ed04c908483e2a543ee1b245606d6529fc87eb54cc34f540d61ba9005958b848d0319b17f06226476c2ef64edf63e8c234b1d6f3338d2209e28224031cf7dcf5f0bad127bce3c669ec6848bb4e4681235ffa0ce0abf83ac45304723e31717fc634cc122b7d8e3eb3cd57604cb5804a9f320906843f43fc3f6e8f1c1670178697ab75705137ca8324f5743f2759f770f0310187b1150032ef4ad747b8fd8a1fe1b9591002b6fac28bac67e5a547b035994dfe12a1cd92bf64fd7229557e0c933d0318a389fb2fe3bfdc8cb885d60e2fa1de786a701a129c8131342178e1830c950324013e8e194da70234ac25f733c3d6a06d7ba\", \"area\": 169751.05240838812, \"lat\": -0.6289281716727779, \"long\": 43.44337246385466, \"is_archived\": false, \"proj_type\": 1, \"user\": 2 } project_type_label : label of the project type the project is associated with. delimitation_field : A geojson object generated from the kml file used to create the project, it is the delimitation polygone of the project on the map. area_file : Link to the kml file of the project, it is the file that contains the delimitation shape of the project on the map. proj_type : id of the project type the project is associated to. user : id of the user the project is associated to","title":"Single project data : project/&lt;id&gt;"},{"location":"Api/Project/#all-projects-data-project","text":"To retrieve the list of all the projects and their data at once you can request the api endpoint /api/project/ : GET / HTTP/1.1 Host: <BASE_URL>/api/project/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains projects data (The list of all projects): [ { \"id\": 1, \"project_type_label\": \"projectType 1\", \"user_username\": \"g_b_m\", \"delimitation_field\": { \"type\": \"FeatureCollection\", \"features\": [ { \"id\": 1, \"type\": \"Feature\", \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -0.628928171672778, 43.44337246385466, 0 ], ..., [ -0.630138420045127, 43.44103583242925, 0 ], [ -0.628928171672778, 43.44337246385466, 0 ] ] ] ] }, \"properties\": { \"project\": 1 } } ] }, \"name\": \"project_test\", \"description\": \"gregreergerw\", \"hubspot_proj_id\": \"johfodsfhof\", \"last_edit\": \"2024-01-26T14:56:29.900846Z\", \"area_file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/Arthez.kml?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T231454Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=3e933fb285a6d71a80a78b838ed04c908483e2a543ee1b245606d6529fc87eb54cc34f540d61ba9005958b848d0319b17f06226476c2ef64edf63e8c234b1d6f3338d2209e28224031cf7dcf5f0bad127bce3c669ec6848bb4e4681235ffa0ce0abf83ac45304723e31717fc634cc122b7d8e3eb3cd57604cb5804a9f320906843f43fc3f6e8f1c1670178697ab75705137ca8324f5743f2759f770f0310187b1150032ef4ad747b8fd8a1fe1b9591002b6fac28bac67e5a547b035994dfe12a1cd92bf64fd7229557e0c933d0318a389fb2fe3bfdc8cb885d60e2fa1de786a701a129c8131342178e1830c950324013e8e194da70234ac25f733c3d6a06d7ba\", \"area\": 169751.05240838812, \"lat\": -0.6289281716727779, \"long\": 43.44337246385466, \"is_archived\": false, \"proj_type\": 1, \"user\": 2 }, { \"id\": 1, \"project_type_label\": \"projectType 1\", \"user_username\": \"g_b_m\", \"delimitation_field\": { \"type\": \"FeatureCollection\", \"features\": [ { \"id\": 1, \"type\": \"Feature\", \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -0.628928171672778, 43.44337246385466, 0 ], ..., [ -0.630138420045127, 43.44103583242925, 0 ], [ -0.628928171672778, 43.44337246385466, 0 ] ] ] ] }, \"properties\": { \"project\": 1 } } ] }, \"name\": \"project_test\", \"description\": \"gregreergerw\", \"hubspot_proj_id\": \"johfodsfhof\", \"last_edit\": \"2024-01-26T14:56:29.900846Z\", \"area_file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/Arthez.kml?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T231454Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=3e933fb285a6d71a80a78b838ed04c908483e2a543ee1b245606d6529fc87eb54cc34f540d61ba9005958b848d0319b17f06226476c2ef64edf63e8c234b1d6f3338d2209e28224031cf7dcf5f0bad127bce3c669ec6848bb4e4681235ffa0ce0abf83ac45304723e31717fc634cc122b7d8e3eb3cd57604cb5804a9f320906843f43fc3f6e8f1c1670178697ab75705137ca8324f5743f2759f770f0310187b1150032ef4ad747b8fd8a1fe1b9591002b6fac28bac67e5a547b035994dfe12a1cd92bf64fd7229557e0c933d0318a389fb2fe3bfdc8cb885d60e2fa1de786a701a129c8131342178e1830c950324013e8e194da70234ac25f733c3d6a06d7ba\", \"area\": 169751.05240838812, \"lat\": -0.6289281716727779, \"long\": 43.44337246385466, \"is_archived\": false, \"proj_type\": 1, \"user\": 2 } ... ... ]","title":"All Projects Data : project/"},{"location":"Api/Project/#delete-project","text":"Important Only ADMIN users can delete projects. To delete a project data you can request the api endpoint /api/project/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/project/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project's id you want to delete. <ACCESS TOKEN> : The connected user's access token.","title":"Delete project"},{"location":"Api/Project/#create-project","text":"Important Only ADMIN or AG_DATA users can create projects with this API. To create a project data you can request the api endpoint /api/project/ : NEEDS TO BE EDITED POST / HTTP/1.1 Host: <BASE_URL>/api/project/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"name\":\"project_2\", \"description\":\"Geographic Data with points\", \"hubspot_proj_id\":\"ffwefw\", \"area_file\":[KML FILE], \"proj_type\":1, \"user\":2 } <ACCESS TOKEN> : The connected user's access token. proj_type : id of the project type the project is associated to. user : id of the user the project is associated to","title":"Create project"},{"location":"Api/Project/#update-project","text":"Important Only ADMIN or AG_DATA users can update projects with this API. To update a project's data you can request the api endpoint /api/project/ : NEEDS TO BE EDITED PUT / HTTP/1.1 Host: <BASE_URL>/api/project/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"name\":\"project_2\", \"description\":\"Geographic Data with points\", \"hubspot_proj_id\":\"ffwefw\", \"area_file\":[KML FILE], \"proj_type\":1, \"user\":2 } <ACCESS TOKEN> : The connected user's access token. <id> : The project's id you want to update.","title":"Update project"},{"location":"Api/Project_File/","text":"Project File API This page regroups a list of API calls to manage the project files for each project. Retrieve data Single Project File data : data/<id> To retrieve a project file data you can request the api endpoint /api/data/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/data/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project file's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected project file's access token. This endpoints response is a json object that contains the project file's data, the project depends on the data type used by the project file: If the file is a shapefile it returns a GEOJson Object If the file is a ANALYTICS file type, it returns a JSON object containing the file's data Raster file To display the raster file on a map you need to retreive the raster id from the project file, then use the Raster Tile API point to retreive the raster tiles depending on x , y , and zoom of the map Retreive raster id: to retreive the raster id from the project file you need to call this API endpoint GET / HTTP/1.1 Host: <BASE_URL>/api/rasterdata/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected project file's access token. <id> : id of the project file from whom you want to retrieve the rater id . The response is as follow : { \"project_file\": 2, \"raster\":36, \"lon\":, \"lat\":, } raster : the raster layer id Retreive raster tiles to retreive the tiles of a raster layer you can use this API endpoint: GET / HTTP/1.1 Host: <BASE_URL>/api/raster/tiles/<layer>/<z>/<x>/<y> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected project file's access token. <layer> : id of the raster layer, retreived with the /api/rasterdata/<id> request . <x> : the x position of the map. <y> : the y position of the map . <z> : the zomm level of the map. This request returns the tile of the raster at the position , , and at the zoom level as an image. You can use this endpoint tp retreive a TileLayer using other libraries like Leadlet - ### All Project Files of a project : projectfile/<id> To retrieve the list of all the project files and their data at once you can request the api endpoint /api/projectfile/<id>/ : GET / HTTP/1.1 Host: <BASE_URL>/api/projectfile/<id>/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected project file's access token. <id> : id of the project whom you want to retrieve the project files. This endpoint response is a list of json objects that contains project files data (The list of all project files): [ { \"id\": 236, \"name\": \"VCLBRAG\", \"description\": \"bclabk\", \"file_type\": \"Geo_File\", \"data_type\": null, \"project\": 1, \"files\": [ { \"id\": 446, \"nbr_chunk\": 8, \"file_name\": \"Orthomosa\u00efque.tif\", \"file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/VCLBRAG/Orthomosa%C3%AFque/Orthomosa%C3%AFque.tif?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240301%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240301T182618Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=373af158405dd8c5a7dc73d24556a30d3f7f2c6aaaeea0ed8928b601999967c9835401298a570594b08f6e678f33cdfc8a601cd7c41eef7e3030c73c7d7a1b800ebd6652e9409edccb79463c3bdf2f978d532dce34aa0c6d5cf5545080f0655396092b5fc0acc1a4508869f0d269ef9eecf2b03924744f9b48a88cb5563eca4ea06740228284e1c7befcb087b303be083b88a8a0e9eebd2c87ea562e2770f1d0d07a46177bc9a487feff7aaad57c246b06c3be6b04d19c9364e034bd15f999d3e652199d7b361fffeb27891542d648d45890bada1e0f5786216c5433619c4ee5c477d744b1dff0f659b5c462889ad1801d69b247e007f43fabc6eac7d703a3c2\", \"to_project_files\": 236 }, ... ... ], \"file_extention\": \"raster\", \"processed\": false, \"error\": false, \"error_message\": \"\" }, { \"id\": 236, \"name\": \"VCLBRAG\", \"description\": \"bclabk\", \"file_type\": \"Geo_File\", \"data_type\": null, \"project\": 1, \"files\": [ { \"id\": 446, \"nbr_chunk\": 8, \"file_name\": \"Orthomosa\u00efque.tif\", \"file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/VCLBRAG/Orthomosa%C3%AFque/Orthomosa%C3%AFque.tif?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240301%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240301T182618Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=373af158405dd8c5a7dc73d24556a30d3f7f2c6aaaeea0ed8928b601999967c9835401298a570594b08f6e678f33cdfc8a601cd7c41eef7e3030c73c7d7a1b800ebd6652e9409edccb79463c3bdf2f978d532dce34aa0c6d5cf5545080f0655396092b5fc0acc1a4508869f0d269ef9eecf2b03924744f9b48a88cb5563eca4ea06740228284e1c7befcb087b303be083b88a8a0e9eebd2c87ea562e2770f1d0d07a46177bc9a487feff7aaad57c246b06c3be6b04d19c9364e034bd15f999d3e652199d7b361fffeb27891542d648d45890bada1e0f5786216c5433619c4ee5c477d744b1dff0f659b5c462889ad1801d69b247e007f43fabc6eac7d703a3c2\", \"to_project_files\": 236 }, ... ... ], \"file_extention\": \"raster\", \"processed\": false, \"error\": false, \"error_message\": \"\" }, ... ... ] Delete Project File Important Only ADMIN project files can delete project files. To delete a projectfile data you can request the api endpoint /api/projectfile/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/projectfile/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project file's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected project file's access token. Upload/Create a Project File Important Only ADMIN or AG_DATA project files can create project files with this API. To create a projectfile data you can request the api endpoint /api/projectfile/<id>/ : first you need to create the projectfile : POST / HTTP/1.1 Host: <BASE_URL>/api/projectfile/<id>/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"name\":\"name of the file\", \"file_ext\":\"file extension id of the project file\", \"data_type\":\"id of the data type used by the project file\", \"project\":\"id of the project linked to the file\", \"description\":\"description of the project file\", } <id> : The project id to whom you want to link the file. <ACCESS TOKEN> : The connected project file's access token. This endpoints response is a json object that contains the project file's data, the project depends on the data type used by the project file: { \"id\":263, \"name\":\"pdf\", \"description\":\"dqdewq\", \"file_type\":\"PDF\", \"data_type\":null, \"project\":1, \"files\":[], \"file_extention\":\"pdf\", \"processed\":false, \"error\":false, \"error_message\":\"\"} Then you need to upload the files (by chunks) to the projectfile using the following requests Important The files are expected to be uploaded by chunks, you need to send the requst for each chunk. You first need to upload the fist chunk with the /api/upload_file/ POST request in order to create the FileChunk ( link to model ). Then if the file has multiple chunks, you upload the rest of the chunks using the /api/upload_file/<id> PUT request. POST / HTTP/1.1 Host: <BASE_URL>/api//api/upload_file/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"to_project_files\":\"name of the file\", \"chunk_file\":\"file extension id of the project file\", \"chunk_index\":\"id of the data type used by the project file\", \"nbr_chunk\":\"id of the project linked to the file\", \"file_name\":\"description of the project file\", } PUT / HTTP/1.1 Host: <BASE_URL>/api//api/upload_file/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"to_project_files\":\"id of the projectfile this file is linked to\", \"chunk_file\":\"file/blob containing the chunk of the main file\", \"chunk_index\":\"index of the chunk relativaly to the main file\", \"nbr_chunk\":\"number of chunks the file is divided to \", \"file_name\":\"main file name\", } <id> : The FileChunk id to whom you want to upload the chunk. <ACCESS TOKEN> : The connected project file's access token. This endpoints response is a json object that contains the file's attributes: { \"id\":499, \"nbr_chunk\":8, \"file_name\":\"Orthomosa\u00efque.tif\", \"file\":null, \"to_project_files\":264 } when all chunks are uploaded and combined, the final chunk upload request returns this response: { \"id\":499, \"nbr_chunk\":8, \"file_name\":\"Orthomosa\u00efque.tif\", \"file\":\"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/PDF/vvsvsdavsa/Orthomosa%C3%AFque/Orthomosa%C3%AFque.tif?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T234224Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=37aa0c996d795d25eed966f326861c2652760ba7f6a29067d991a68b73dd73ca67a6c29bc15d5ecb4bf6499c1d6148fcf1eb9f08074d31e6542bd16b61dc78a3e994233f1d4efb2eb7ee567599c09754c7ced4bbc5e6dd7f80d5ce2eb3e8e552388f4b3559d9d2b03963df3d61d64eb55d2d2890231e806b30e9175052b6732410ab15a92d771f81d46cdce6499c4d70f34ac03025cd9a43e1546941b03bdd2434a722659bcd7cf6885dfae22c0e2f8a9774ff4cc877d2df31876aa82886252088eb694a368449bbae5ef19c5972225f73ec52c124290679694e92f4a8620dddc4456e384b6b6a9c0b1917674aac70daab09fc05c6debcd4122a8df6e8b38861\", \"to_project_files\":264 } file : url of the uploaded file in the cloud storage Process a Project File Note After uploading all the chunks of the files related to a ProjectFile , you need to call api/process_file/<id> to process the ProjectFile GET / HTTP/1.1 Host: <BASE_URL>/api//api/upload_file/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json The response for this request is the processing state of the file, either a successeful response or an error response containing the error that occured. ProjectFile LayerOrder on the map","title":"Project File API"},{"location":"Api/Project_File/#project-file-api","text":"This page regroups a list of API calls to manage the project files for each project.","title":"Project File API"},{"location":"Api/Project_File/#retrieve-data","text":"","title":"Retrieve data"},{"location":"Api/Project_File/#single-project-file-data-dataid","text":"To retrieve a project file data you can request the api endpoint /api/data/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/data/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project file's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected project file's access token. This endpoints response is a json object that contains the project file's data, the project depends on the data type used by the project file: If the file is a shapefile it returns a GEOJson Object If the file is a ANALYTICS file type, it returns a JSON object containing the file's data","title":"Single Project File data : data/&lt;id&gt;"},{"location":"Api/Project_File/#raster-file","text":"To display the raster file on a map you need to retreive the raster id from the project file, then use the Raster Tile API point to retreive the raster tiles depending on x , y , and zoom of the map","title":"Raster file"},{"location":"Api/Project_File/#retreive-raster-id","text":"to retreive the raster id from the project file you need to call this API endpoint GET / HTTP/1.1 Host: <BASE_URL>/api/rasterdata/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected project file's access token. <id> : id of the project file from whom you want to retrieve the rater id . The response is as follow : { \"project_file\": 2, \"raster\":36, \"lon\":, \"lat\":, } raster : the raster layer id","title":"Retreive raster id:"},{"location":"Api/Project_File/#retreive-raster-tiles","text":"to retreive the tiles of a raster layer you can use this API endpoint: GET / HTTP/1.1 Host: <BASE_URL>/api/raster/tiles/<layer>/<z>/<x>/<y> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected project file's access token. <layer> : id of the raster layer, retreived with the /api/rasterdata/<id> request . <x> : the x position of the map. <y> : the y position of the map . <z> : the zomm level of the map. This request returns the tile of the raster at the position , , and at the zoom level as an image. You can use this endpoint tp retreive a TileLayer using other libraries like Leadlet - ### All Project Files of a project : projectfile/<id> To retrieve the list of all the project files and their data at once you can request the api endpoint /api/projectfile/<id>/ : GET / HTTP/1.1 Host: <BASE_URL>/api/projectfile/<id>/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected project file's access token. <id> : id of the project whom you want to retrieve the project files. This endpoint response is a list of json objects that contains project files data (The list of all project files): [ { \"id\": 236, \"name\": \"VCLBRAG\", \"description\": \"bclabk\", \"file_type\": \"Geo_File\", \"data_type\": null, \"project\": 1, \"files\": [ { \"id\": 446, \"nbr_chunk\": 8, \"file_name\": \"Orthomosa\u00efque.tif\", \"file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/VCLBRAG/Orthomosa%C3%AFque/Orthomosa%C3%AFque.tif?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240301%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240301T182618Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=373af158405dd8c5a7dc73d24556a30d3f7f2c6aaaeea0ed8928b601999967c9835401298a570594b08f6e678f33cdfc8a601cd7c41eef7e3030c73c7d7a1b800ebd6652e9409edccb79463c3bdf2f978d532dce34aa0c6d5cf5545080f0655396092b5fc0acc1a4508869f0d269ef9eecf2b03924744f9b48a88cb5563eca4ea06740228284e1c7befcb087b303be083b88a8a0e9eebd2c87ea562e2770f1d0d07a46177bc9a487feff7aaad57c246b06c3be6b04d19c9364e034bd15f999d3e652199d7b361fffeb27891542d648d45890bada1e0f5786216c5433619c4ee5c477d744b1dff0f659b5c462889ad1801d69b247e007f43fabc6eac7d703a3c2\", \"to_project_files\": 236 }, ... ... ], \"file_extention\": \"raster\", \"processed\": false, \"error\": false, \"error_message\": \"\" }, { \"id\": 236, \"name\": \"VCLBRAG\", \"description\": \"bclabk\", \"file_type\": \"Geo_File\", \"data_type\": null, \"project\": 1, \"files\": [ { \"id\": 446, \"nbr_chunk\": 8, \"file_name\": \"Orthomosa\u00efque.tif\", \"file\": \"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/VCLBRAG/Orthomosa%C3%AFque/Orthomosa%C3%AFque.tif?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240301%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240301T182618Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=373af158405dd8c5a7dc73d24556a30d3f7f2c6aaaeea0ed8928b601999967c9835401298a570594b08f6e678f33cdfc8a601cd7c41eef7e3030c73c7d7a1b800ebd6652e9409edccb79463c3bdf2f978d532dce34aa0c6d5cf5545080f0655396092b5fc0acc1a4508869f0d269ef9eecf2b03924744f9b48a88cb5563eca4ea06740228284e1c7befcb087b303be083b88a8a0e9eebd2c87ea562e2770f1d0d07a46177bc9a487feff7aaad57c246b06c3be6b04d19c9364e034bd15f999d3e652199d7b361fffeb27891542d648d45890bada1e0f5786216c5433619c4ee5c477d744b1dff0f659b5c462889ad1801d69b247e007f43fabc6eac7d703a3c2\", \"to_project_files\": 236 }, ... ... ], \"file_extention\": \"raster\", \"processed\": false, \"error\": false, \"error_message\": \"\" }, ... ... ]","title":"Retreive raster tiles"},{"location":"Api/Project_File/#delete-project-file","text":"Important Only ADMIN project files can delete project files. To delete a projectfile data you can request the api endpoint /api/projectfile/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/projectfile/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project file's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected project file's access token.","title":"Delete Project File"},{"location":"Api/Project_File/#uploadcreate-a-project-file","text":"Important Only ADMIN or AG_DATA project files can create project files with this API. To create a projectfile data you can request the api endpoint /api/projectfile/<id>/ : first you need to create the projectfile : POST / HTTP/1.1 Host: <BASE_URL>/api/projectfile/<id>/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"name\":\"name of the file\", \"file_ext\":\"file extension id of the project file\", \"data_type\":\"id of the data type used by the project file\", \"project\":\"id of the project linked to the file\", \"description\":\"description of the project file\", } <id> : The project id to whom you want to link the file. <ACCESS TOKEN> : The connected project file's access token. This endpoints response is a json object that contains the project file's data, the project depends on the data type used by the project file: { \"id\":263, \"name\":\"pdf\", \"description\":\"dqdewq\", \"file_type\":\"PDF\", \"data_type\":null, \"project\":1, \"files\":[], \"file_extention\":\"pdf\", \"processed\":false, \"error\":false, \"error_message\":\"\"} Then you need to upload the files (by chunks) to the projectfile using the following requests Important The files are expected to be uploaded by chunks, you need to send the requst for each chunk. You first need to upload the fist chunk with the /api/upload_file/ POST request in order to create the FileChunk ( link to model ). Then if the file has multiple chunks, you upload the rest of the chunks using the /api/upload_file/<id> PUT request. POST / HTTP/1.1 Host: <BASE_URL>/api//api/upload_file/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"to_project_files\":\"name of the file\", \"chunk_file\":\"file extension id of the project file\", \"chunk_index\":\"id of the data type used by the project file\", \"nbr_chunk\":\"id of the project linked to the file\", \"file_name\":\"description of the project file\", } PUT / HTTP/1.1 Host: <BASE_URL>/api//api/upload_file/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"to_project_files\":\"id of the projectfile this file is linked to\", \"chunk_file\":\"file/blob containing the chunk of the main file\", \"chunk_index\":\"index of the chunk relativaly to the main file\", \"nbr_chunk\":\"number of chunks the file is divided to \", \"file_name\":\"main file name\", } <id> : The FileChunk id to whom you want to upload the chunk. <ACCESS TOKEN> : The connected project file's access token. This endpoints response is a json object that contains the file's attributes: { \"id\":499, \"nbr_chunk\":8, \"file_name\":\"Orthomosa\u00efque.tif\", \"file\":null, \"to_project_files\":264 } when all chunks are uploaded and combined, the final chunk upload request returns this response: { \"id\":499, \"nbr_chunk\":8, \"file_name\":\"Orthomosa\u00efque.tif\", \"file\":\"https://storage.googleapis.com/inthe_bucket/projects/projectType%201/project_test/PDF/vvsvsdavsa/Orthomosa%C3%AFque/Orthomosa%C3%AFque.tif?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=inthe-account-med%40natural-point-401007.iam.gserviceaccount.com%2F20240328%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240328T234224Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=37aa0c996d795d25eed966f326861c2652760ba7f6a29067d991a68b73dd73ca67a6c29bc15d5ecb4bf6499c1d6148fcf1eb9f08074d31e6542bd16b61dc78a3e994233f1d4efb2eb7ee567599c09754c7ced4bbc5e6dd7f80d5ce2eb3e8e552388f4b3559d9d2b03963df3d61d64eb55d2d2890231e806b30e9175052b6732410ab15a92d771f81d46cdce6499c4d70f34ac03025cd9a43e1546941b03bdd2434a722659bcd7cf6885dfae22c0e2f8a9774ff4cc877d2df31876aa82886252088eb694a368449bbae5ef19c5972225f73ec52c124290679694e92f4a8620dddc4456e384b6b6a9c0b1917674aac70daab09fc05c6debcd4122a8df6e8b38861\", \"to_project_files\":264 } file : url of the uploaded file in the cloud storage","title":"Upload/Create a Project File"},{"location":"Api/Project_File/#process-a-project-file","text":"Note After uploading all the chunks of the files related to a ProjectFile , you need to call api/process_file/<id> to process the ProjectFile GET / HTTP/1.1 Host: <BASE_URL>/api//api/upload_file/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json The response for this request is the processing state of the file, either a successeful response or an error response containing the error that occured.","title":"Process a Project File"},{"location":"Api/Project_File/#projectfile-layerorder-on-the-map","text":"","title":"ProjectFile LayerOrder on the map"},{"location":"Api/Sector/","text":"Sectors Endpoints This page regroups a set of endpoints to interact with the sectors related data. Retrieve data Single sector data : sector/<id> To retrieve a sector data you can request the api endpoint /api/sector/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/sector/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The sector's id of whom you want to retrieve data, it is the \"activity_sector\" property. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the sector's data: { \"activity_sector\": \"activity sector label\", \"description\": \"activity sector description\", } All sectors Data : sector/ To retrieve the list of all the sectors and their data at once you can request the api endpoint /api/sector/ : GET / HTTP/1.1 Host: <BASE_URL>/api/sector/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains sectors data (The list of all sectors): [ { \"activity_sector\": \"sector \", \"description\": \"description\", }, { \"activity_sector\": \"sector 2\", \"description\": \"description\", }, ... ... ] Delete Sector Important Only ADMIN users can delete sectors. To delete a sector data you can request the api endpoint /api/sector/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/sector/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The sector's id of whom you want to retrieve data, it is the \"activity_sector\" property. <ACCESS TOKEN> : The connected user's access token. Create Sector Important Only ADMIN or AG_DATA users can create sectors with this API. To create a sector data you can request the api endpoint /api/sector/ : POST / HTTP/1.1 Host: <BASE_URL>/api/sector/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"activity_sector\": \"activity sector label\", \"description\": \"activity sector description\", } <ACCESS TOKEN> : The connected user's access token.","title":"Sectors Endpoints"},{"location":"Api/Sector/#sectors-endpoints","text":"This page regroups a set of endpoints to interact with the sectors related data.","title":"Sectors Endpoints"},{"location":"Api/Sector/#retrieve-data","text":"","title":"Retrieve data"},{"location":"Api/Sector/#single-sector-data-sectorid","text":"To retrieve a sector data you can request the api endpoint /api/sector/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/sector/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The sector's id of whom you want to retrieve data, it is the \"activity_sector\" property. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the sector's data: { \"activity_sector\": \"activity sector label\", \"description\": \"activity sector description\", }","title":"Single sector data : sector/&lt;id&gt;"},{"location":"Api/Sector/#all-sectors-data-sector","text":"To retrieve the list of all the sectors and their data at once you can request the api endpoint /api/sector/ : GET / HTTP/1.1 Host: <BASE_URL>/api/sector/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains sectors data (The list of all sectors): [ { \"activity_sector\": \"sector \", \"description\": \"description\", }, { \"activity_sector\": \"sector 2\", \"description\": \"description\", }, ... ... ]","title":"All sectors Data : sector/"},{"location":"Api/Sector/#delete-sector","text":"Important Only ADMIN users can delete sectors. To delete a sector data you can request the api endpoint /api/sector/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/sector/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The sector's id of whom you want to retrieve data, it is the \"activity_sector\" property. <ACCESS TOKEN> : The connected user's access token.","title":"Delete Sector"},{"location":"Api/Sector/#create-sector","text":"Important Only ADMIN or AG_DATA users can create sectors with this API. To create a sector data you can request the api endpoint /api/sector/ : POST / HTTP/1.1 Host: <BASE_URL>/api/sector/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"activity_sector\": \"activity sector label\", \"description\": \"activity sector description\", } <ACCESS TOKEN> : The connected user's access token.","title":"Create Sector"},{"location":"Api/Types/","text":"Types API This page contains all the api calls to handle the different types used by the saas platform Project Types Project types are labels that define projects domain or field, it is a classification label that enables advanced queries. Retrieve data Single Project Type data : projecttype/<id> To retrieve a project type data you can request the api endpoint /api/projecttype/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/projecttype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project type's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the project types's data: { \"id\":1, \"label\":\"project type 1\" } All Project Types Data : projecttype/ To retrieve the list of all the project types and their data at once you can request the api endpoint /api/projecttype/ : GET / HTTP/1.1 Host: <BASE_URL>/api/projecttype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains project types data (The list of all project types): [ { \"id\":1, \"label\":\"project type 1\" }, { \"id\":2, \"label\":\"project type 2\" }, ... ... ] Delete Project Types Important Only ADMIN users can delete project types. To delete a project type you can request the api endpoint /api/projecttype/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/projecttype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project type's id of whom you want to delete. <ACCESS TOKEN> : The connected user's access token. Create Project Type Important Only ADMIN or AG_DATA users can create project types with this API. To create a project type data you can request the api endpoint /api/projecttype/ : POST / HTTP/1.1 Host: <BASE_URL>/api/projecttype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"label\": \"project type's label\", } <ACCESS TOKEN> : The connected user's access token. File Types File Types are labels that defines the type of file used in a project, it enables a process selection to process the file depending on its type, but also enables advanced queries. Retrieve data Single file type data : filetype/<id> To retrieve a file type data you can request the api endpoint /api/filetype/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/filetype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The file type's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the filetype's data: { \"id\":1, \"label\":\"Geo_File\", \"description\":\"Files that contains Geo Data\" } All File Types Data : filetype/ To retrieve the list of all the file types and their data at once you can request the api endpoint /api/filetype/ : GET / HTTP/1.1 Host: <BASE_URL>/api/filetype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains file types data (The list of all file types): [ { \"id\":1, \"label\":\"Geo_File\", \"description\":\"Files that contains Geo Data\" }, { \"id\":2, \"label\":\"Analytics\", \"description\":\"Files that contains Annalytic Data\" }, { \"id\":3, \"label\":\"3D\", \"description\":\"3D Files\" }, { \"id\":4, \"label\":\"Images\", \"description\":\"Image Files\" }, { \"id\":5, \"label\":\"PDF\", \"description\":\"PDF Compressed files\" } ... ... ] Delete File Type Important Only ADMIN users can delete filetypes. To delete a filetype data you can request the api endpoint /api/filetype/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/filetype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The file type's id of whom you want to delete data. <ACCESS TOKEN> : The connected user's access token. Create File Type Important Only ADMIN or AG_DATA users can create file types with this API. To create a file type data you can request the api endpoint /api/filetype/ : POST / HTTP/1.1 Host: <BASE_URL>/api/filetype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"label\":\"file type label\", \"description\":\"file type description\" } <ACCESS TOKEN> : The connected user's access token. Data Types Data Types are labels that defines the type of data used in a file, it enables a visualization and processing selection to process the and display the data in each file depending on its type, it also enables advanced queries and classification. Retrieve data To retrieve the list of all the datatypes and their data at once you can request the api endpoint /api/datatype/ : GET / HTTP/1.1 Host: <BASE_URL>/api/datatype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains datatypes data (The list of all datatypes): [ { \"id\":1, \"label\":\"data type label\", \"description\":\"data type description\", \"fields\":[ \"field_1\", \"field_2\", \"field_3\", \"field_4\", ... ... ] }, { \"id\":2, \"label\":\"data type label\", \"description\":\"data type description\", \"fields\":[ \"field_1\", \"field_2\", \"field_3\", \"field_4\", ... ... ] }, ... ... ] Delete datatype Important Only ADMIN users can delete data types. To delete a datatype data you can request the api endpoint /api/datatype/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/datatype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The datatype's id you wanna delete. <ACCESS TOKEN> : The connected user's access token. Create datatype Important Only ADMIN or AG_DATA users can create data types with this API. To create a datatype data you can request the api endpoint /api/datatype/ : POST / HTTP/1.1 Host: <BASE_URL>/api/datatype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"label\": \"data type label\", \"description\": \"data type description\", \"uploaded_files\": [XLSX File OR SHP File and its dependencies] } <ACCESS TOKEN> : The connected user's access token. File Extensions File Extensions are labels that defines the extension of a file, it is used to define the technology used for a file, but also enables an advanced classification. Each File Extension is linked to a File Type Retrieve data To retrieve the list of all the file Extensions at once you can request the api endpoint /api/fileext/ : GET / HTTP/1.1 Host: <BASE_URL>/api/fileext/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains file Extensions data (The list of all file Extensions): [ { \"id\":3, \"extention\":\"pdf\", \"file_type\":5 }, { \"id\":2, \"extention\":\"png\", \"file_type\":6 }, ... ... ] Delete File Extensions Important Only ADMIN users can delete data types. To delete a file Extensions data you can request the api endpoint /api/fileext/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/fileext/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The file Extension's id you wanna delete. <ACCESS TOKEN> : The connected user's access token. Create File Extensions Important Only ADMIN or AG_DATA users can create data types with this API. To create a file Extensions data you can request the api endpoint /api/fileext/ : POST / HTTP/1.1 Host: <BASE_URL>/api/fileext/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"extention\": \"extension label\", \"file_type\": \"id of the file type linked to the extension } <ACCESS TOKEN> : The connected user's access token.","title":"Types API"},{"location":"Api/Types/#types-api","text":"This page contains all the api calls to handle the different types used by the saas platform","title":"Types API"},{"location":"Api/Types/#project-types","text":"Project types are labels that define projects domain or field, it is a classification label that enables advanced queries.","title":"Project Types"},{"location":"Api/Types/#retrieve-data","text":"","title":"Retrieve data"},{"location":"Api/Types/#single-project-type-data-projecttypeid","text":"To retrieve a project type data you can request the api endpoint /api/projecttype/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/projecttype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project type's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the project types's data: { \"id\":1, \"label\":\"project type 1\" }","title":"Single Project Type data : projecttype/&lt;id&gt;"},{"location":"Api/Types/#all-project-types-data-projecttype","text":"To retrieve the list of all the project types and their data at once you can request the api endpoint /api/projecttype/ : GET / HTTP/1.1 Host: <BASE_URL>/api/projecttype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains project types data (The list of all project types): [ { \"id\":1, \"label\":\"project type 1\" }, { \"id\":2, \"label\":\"project type 2\" }, ... ... ]","title":"All Project Types Data : projecttype/"},{"location":"Api/Types/#delete-project-types","text":"Important Only ADMIN users can delete project types. To delete a project type you can request the api endpoint /api/projecttype/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/projecttype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The project type's id of whom you want to delete. <ACCESS TOKEN> : The connected user's access token.","title":"Delete Project Types"},{"location":"Api/Types/#create-project-type","text":"Important Only ADMIN or AG_DATA users can create project types with this API. To create a project type data you can request the api endpoint /api/projecttype/ : POST / HTTP/1.1 Host: <BASE_URL>/api/projecttype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"label\": \"project type's label\", } <ACCESS TOKEN> : The connected user's access token.","title":"Create Project Type"},{"location":"Api/Types/#file-types","text":"File Types are labels that defines the type of file used in a project, it enables a process selection to process the file depending on its type, but also enables advanced queries.","title":"File Types"},{"location":"Api/Types/#retrieve-data_1","text":"","title":"Retrieve data"},{"location":"Api/Types/#single-file-type-data-filetypeid","text":"To retrieve a file type data you can request the api endpoint /api/filetype/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/filetype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The file type's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. This endpoints response is a json object that contains the filetype's data: { \"id\":1, \"label\":\"Geo_File\", \"description\":\"Files that contains Geo Data\" }","title":"Single file type data : filetype/&lt;id&gt;"},{"location":"Api/Types/#all-file-types-data-filetype","text":"To retrieve the list of all the file types and their data at once you can request the api endpoint /api/filetype/ : GET / HTTP/1.1 Host: <BASE_URL>/api/filetype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains file types data (The list of all file types): [ { \"id\":1, \"label\":\"Geo_File\", \"description\":\"Files that contains Geo Data\" }, { \"id\":2, \"label\":\"Analytics\", \"description\":\"Files that contains Annalytic Data\" }, { \"id\":3, \"label\":\"3D\", \"description\":\"3D Files\" }, { \"id\":4, \"label\":\"Images\", \"description\":\"Image Files\" }, { \"id\":5, \"label\":\"PDF\", \"description\":\"PDF Compressed files\" } ... ... ]","title":"All File Types Data : filetype/"},{"location":"Api/Types/#delete-file-type","text":"Important Only ADMIN users can delete filetypes. To delete a filetype data you can request the api endpoint /api/filetype/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/filetype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The file type's id of whom you want to delete data. <ACCESS TOKEN> : The connected user's access token.","title":"Delete File Type"},{"location":"Api/Types/#create-file-type","text":"Important Only ADMIN or AG_DATA users can create file types with this API. To create a file type data you can request the api endpoint /api/filetype/ : POST / HTTP/1.1 Host: <BASE_URL>/api/filetype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"label\":\"file type label\", \"description\":\"file type description\" } <ACCESS TOKEN> : The connected user's access token.","title":"Create File Type"},{"location":"Api/Types/#data-types","text":"Data Types are labels that defines the type of data used in a file, it enables a visualization and processing selection to process the and display the data in each file depending on its type, it also enables advanced queries and classification.","title":"Data Types"},{"location":"Api/Types/#retrieve-data_2","text":"To retrieve the list of all the datatypes and their data at once you can request the api endpoint /api/datatype/ : GET / HTTP/1.1 Host: <BASE_URL>/api/datatype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains datatypes data (The list of all datatypes): [ { \"id\":1, \"label\":\"data type label\", \"description\":\"data type description\", \"fields\":[ \"field_1\", \"field_2\", \"field_3\", \"field_4\", ... ... ] }, { \"id\":2, \"label\":\"data type label\", \"description\":\"data type description\", \"fields\":[ \"field_1\", \"field_2\", \"field_3\", \"field_4\", ... ... ] }, ... ... ]","title":"Retrieve data"},{"location":"Api/Types/#delete-datatype","text":"Important Only ADMIN users can delete data types. To delete a datatype data you can request the api endpoint /api/datatype/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/datatype/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The datatype's id you wanna delete. <ACCESS TOKEN> : The connected user's access token.","title":"Delete datatype"},{"location":"Api/Types/#create-datatype","text":"Important Only ADMIN or AG_DATA users can create data types with this API. To create a datatype data you can request the api endpoint /api/datatype/ : POST / HTTP/1.1 Host: <BASE_URL>/api/datatype/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"label\": \"data type label\", \"description\": \"data type description\", \"uploaded_files\": [XLSX File OR SHP File and its dependencies] } <ACCESS TOKEN> : The connected user's access token.","title":"Create datatype"},{"location":"Api/Types/#file-extensions","text":"File Extensions are labels that defines the extension of a file, it is used to define the technology used for a file, but also enables an advanced classification. Each File Extension is linked to a File Type","title":"File Extensions"},{"location":"Api/Types/#retrieve-data_3","text":"To retrieve the list of all the file Extensions at once you can request the api endpoint /api/fileext/ : GET / HTTP/1.1 Host: <BASE_URL>/api/fileext/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. This endpoint response is a list of json objects that contains file Extensions data (The list of all file Extensions): [ { \"id\":3, \"extention\":\"pdf\", \"file_type\":5 }, { \"id\":2, \"extention\":\"png\", \"file_type\":6 }, ... ... ]","title":"Retrieve data"},{"location":"Api/Types/#delete-file-extensions","text":"Important Only ADMIN users can delete data types. To delete a file Extensions data you can request the api endpoint /api/fileext/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/fileext/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The file Extension's id you wanna delete. <ACCESS TOKEN> : The connected user's access token.","title":"Delete File Extensions"},{"location":"Api/Types/#create-file-extensions","text":"Important Only ADMIN or AG_DATA users can create data types with this API. To create a file Extensions data you can request the api endpoint /api/fileext/ : POST / HTTP/1.1 Host: <BASE_URL>/api/fileext/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"extention\": \"extension label\", \"file_type\": \"id of the file type linked to the extension } <ACCESS TOKEN> : The connected user's access token.","title":"Create File Extensions"},{"location":"Api/User/","text":"User Endpoints This page regroups a set of endpoints to interact with the users related data. Retrieve data Single user data : user/<id> To retrieve a user data you can request the api endpoint /api/user/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/user/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The user's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. Important If a user is a CLIENT type, he will only access and retrieve his own data via the API. If the user is a ADMIN or AG_DATA type, then he can access all the users data via the API. This endpoints response is a json object that contains the user's data: { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true } All users Data : user/ To retrieve the list of all the users and their data at once you can request the api endpoint /api/user/ : GET / HTTP/1.1 Host: <BASE_URL>/api/user/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. Important If a user is a CLIENT type, he will only access and retrieve his own data via the API. If the user is a ADMIN or AG_DATA type, then he can access all the users data via the API. This endpoint response is a list of json objects that contains users data (The list of all users): [ { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true }, { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true }, ... ... ] Update User data To update a user data you can request the api endpoint /api/user/<id> : PUT / HTTP/1.1 Host: <BASE_URL>/api/user/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"email\":\"user@gmail.com\", \"username\":\"user_test\", \"first_name\":\"user\", \"last_name\":\"test test\", \"telephone_number\":\"0612345678\", \"position\":\"dev\", \"linkedin_url\":\"https://user.linkedin.com\", \"company\":\"company\", \"user_type\":\"CLIENT\", } <id> : The user's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. Important If a user is a CLIENT type, he can only update his own data via this API endpoint and can't update his password. If the user is a ADMIN or AG_DATA type, then he can update all the users data via this API call, he can also change user's password by adding the propriety \"password\" : \"new pass\" to the body object. This endpoints response is a json object that contains the new user's data: { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true } Delete User Important Only ADMIN users can delete users. To delete a user data you can request the api endpoint /api/user/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/user/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The user's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. Create User Important Only ADMIN or AG_DATA users can create users with this API. To create a user data you can request the api endpoint /api/user/ : POST / HTTP/1.1 Host: <BASE_URL>/api/user/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"email\":\"user@gmail.com\", \"username\":\"user_test\", \"first_name\":\"user\", \"last_name\":\"test test\", \"telephone_number\":\"0612345678\", \"position\":\"dev\", \"linkedin_url\":\"https://user.linkedin.com\", \"password\": \"user password\", \"company\":\"company\", \"user_type\":\"CLIENT\", } <ACCESS TOKEN> : The connected user's access token. Change Password This endpoint is for CLIENT type users to enable them to change their password. To change the users password you need to call the api /api/passwordchange/ . POST / HTTP/1.1 Host: <BASE_URL>/api/passwordchange/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"old_password\": \"Old user's password\", \"new_password\": \"New user's password\", } <ACCESS TOKEN> : The connected user's access token.","title":"User Endpoints"},{"location":"Api/User/#user-endpoints","text":"This page regroups a set of endpoints to interact with the users related data.","title":"User Endpoints"},{"location":"Api/User/#retrieve-data","text":"","title":"Retrieve data"},{"location":"Api/User/#single-user-data-userid","text":"To retrieve a user data you can request the api endpoint /api/user/<id> : GET / HTTP/1.1 Host: <BASE_URL>/api/user/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The user's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. Important If a user is a CLIENT type, he will only access and retrieve his own data via the API. If the user is a ADMIN or AG_DATA type, then he can access all the users data via the API. This endpoints response is a json object that contains the user's data: { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true }","title":"Single user data : user/&lt;id&gt;"},{"location":"Api/User/#all-users-data-user","text":"To retrieve the list of all the users and their data at once you can request the api endpoint /api/user/ : GET / HTTP/1.1 Host: <BASE_URL>/api/user/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <ACCESS TOKEN> : The connected user's access token. Important If a user is a CLIENT type, he will only access and retrieve his own data via the API. If the user is a ADMIN or AG_DATA type, then he can access all the users data via the API. This endpoint response is a list of json objects that contains users data (The list of all users): [ { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true }, { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true }, ... ... ]","title":"All users Data : user/"},{"location":"Api/User/#update-user-data","text":"To update a user data you can request the api endpoint /api/user/<id> : PUT / HTTP/1.1 Host: <BASE_URL>/api/user/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"email\":\"user@gmail.com\", \"username\":\"user_test\", \"first_name\":\"user\", \"last_name\":\"test test\", \"telephone_number\":\"0612345678\", \"position\":\"dev\", \"linkedin_url\":\"https://user.linkedin.com\", \"company\":\"company\", \"user_type\":\"CLIENT\", } <id> : The user's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token. Important If a user is a CLIENT type, he can only update his own data via this API endpoint and can't update his password. If the user is a ADMIN or AG_DATA type, then he can update all the users data via this API call, he can also change user's password by adding the propriety \"password\" : \"new pass\" to the body object. This endpoints response is a json object that contains the new user's data: { \"id\": 4, \"last_login\": \"2023-12-13T10:05:19Z\", \"last_edit_date\": \"2023-12-13T10:05:19.029683Z\", \"email\": \"data2@gmail.com\", \"username\": \"user_test_data\", \"first_name\": \"user\", \"last_name\": \"user\", \"telephone_number\": \"0612345789\", \"position\": \"feqwfewfewf\", \"linkedin_url\": \"\", \"hubspot_user_id\": \"wfwqfdfwefewfewf\", \"company\": \"intheair\", \"company_id\": 1, \"user_type\": \"AG_DATA\", \"is_superuser\": true, \"is_staff\": true }","title":"Update User data"},{"location":"Api/User/#delete-user","text":"Important Only ADMIN users can delete users. To delete a user data you can request the api endpoint /api/user/<id> : DELETE / HTTP/1.1 Host: <BASE_URL>/api/user/<id> Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json <id> : The user's id of whom you want to retrieve data. <ACCESS TOKEN> : The connected user's access token.","title":"Delete User"},{"location":"Api/User/#create-user","text":"Important Only ADMIN or AG_DATA users can create users with this API. To create a user data you can request the api endpoint /api/user/ : POST / HTTP/1.1 Host: <BASE_URL>/api/user/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"email\":\"user@gmail.com\", \"username\":\"user_test\", \"first_name\":\"user\", \"last_name\":\"test test\", \"telephone_number\":\"0612345678\", \"position\":\"dev\", \"linkedin_url\":\"https://user.linkedin.com\", \"password\": \"user password\", \"company\":\"company\", \"user_type\":\"CLIENT\", } <ACCESS TOKEN> : The connected user's access token.","title":"Create User"},{"location":"Api/User/#change-password","text":"This endpoint is for CLIENT type users to enable them to change their password. To change the users password you need to call the api /api/passwordchange/ . POST / HTTP/1.1 Host: <BASE_URL>/api/passwordchange/ Header: Authorization: Bearer <ACCESS TOKEN> Content-Type: application/json Body: { \"old_password\": \"Old user's password\", \"new_password\": \"New user's password\", } <ACCESS TOKEN> : The connected user's access token.","title":"Change Password"},{"location":"Apps/Authentication/","text":"","title":"Authentication"},{"location":"Apps/Authentication/#_1","text":"","title":""},{"location":"Apps/Permissions/","text":"Permissions The backend is working with different permissions in order to manage the access to the backend resources. This page explains what are the different permissions and what they can give access to.","title":"Permissions"},{"location":"Apps/Permissions/#permissions","text":"The backend is working with different permissions in order to manage the access to the backend resources. This page explains what are the different permissions and what they can give access to.","title":"Permissions"},{"location":"Apps/contact/CONTACT/","text":"Description This is the Contact App Documentation ! 1. Models 2. Views 3. Serializers","title":"Description"},{"location":"Apps/contact/CONTACT/#description","text":"This is the Contact App Documentation !","title":"Description"},{"location":"Apps/contact/CONTACT/#1-models","text":"","title":"1. Models"},{"location":"Apps/contact/CONTACT/#2-views","text":"","title":"2. Views"},{"location":"Apps/contact/CONTACT/#3-serializers","text":"","title":"3. Serializers"},{"location":"Apps/contact/MODELS/","text":"","title":"MODELS"},{"location":"Apps/contact/SERIALIZERS/","text":"","title":"SERIALIZERS"},{"location":"Apps/contact/VIEWS/","text":"","title":"VIEWS"},{"location":"Apps/files/FILES/","text":"Files App >> Go back to Home Menu << This is the Files App Documentation ! 1. Models 2. Views 3. Serializers 4. Scripts","title":"Files App"},{"location":"Apps/files/FILES/#files-app","text":">> Go back to Home Menu << This is the Files App Documentation !","title":"Files App"},{"location":"Apps/files/FILES/#1-models","text":"","title":"1. Models"},{"location":"Apps/files/FILES/#2-views","text":"","title":"2. Views"},{"location":"Apps/files/FILES/#3-serializers","text":"","title":"3. Serializers"},{"location":"Apps/files/FILES/#4-scripts","text":"","title":"4. Scripts"},{"location":"Apps/files/MODELS/","text":"Models The files are handled by the App like files in a folder, the folder being the ProjectFile instance and the files in the folder are the files uploaded by the user saved as FileChunk instances. The FileChunk instance having a foreign key to the ProjectFile instance. ProjectFile Class which instances represents the files uploaded by the AG_DATA users and that are meant to be seen and downloaded by CLIENT users, as well as visualized on the platform. class ProjectFile(models.Model): name = models.CharField(max_length=50, unique=True) description = models.CharField(max_length=500) file_type = models.ForeignKey(FileType, on_delete=models.CASCADE, null=True) file_extention = models.ForeignKey(FileExtention, on_delete=models.CASCADE, null=True) data_type = models.ForeignKey(DataType, on_delete=models.CASCADE, null=True) date = models.DateField(auto_now=True) project = models.ForeignKey(Projects, on_delete=models.CASCADE, null=True, related_name=\"to_project\") processed = models.BooleanField(default=False) error = models.BooleanField(default=False) error_message = models.CharField(max_length=500) def __str__(self): return self.name @property def allowed(self): return (self.project.user,) file_type : foreign key to FileType instance representing the file type (visualization mode) data_type : foreign key to DataType instance representing to what table the data should be extracted. project : foreign key to Project instance representing to what project the file is linked CallBacks post_delete_file() This callback delete the related files from the Storage System thus freeing space by removing unused files. post_save_Project_File() This callback create a LayerOrder instance for the file if it is a GEO_FILE instance ( GEO_FILE is a FileType instance). It gives priority, putting them on top level, to files that has a data_type linked to them, thus files who are not rasters . LayerOrder These instances represents the layers dispositions on the map, GEO_FILE with higher order number are displayed over GEO_FILE with lower ones. class LayerOrder(models.Model): project_file = models.OneToOneField(ProjectFile, on_delete=models.CASCADE, primary_key=True) order = models.IntegerField(default=1) FileType Each ProjectType instance has a FileType attribute that represent how the file should be visualized for example GEO_FILE will be visualized on maps, ANALYTICS in tables, IMAGES on pup ups etc.. You can check the Class Structure using this link : Link For Class Structure class FileType(models.Model): label = models.CharField(max_length=50, unique=True) description = models.CharField(max_length=500) def __str__(self): return self.label DataType Each ProjectType instance has a DataType attribute that represents how the file should be processed and where its data should be stored. In other words, it represents in what table the parsed data from the file will be stored, and what function will be used to parse de data You can check the Class Structure using this link : Link For Class Structure class DataType(models.Model): label = models.CharField(max_length=50, unique=True) description = models.CharField(max_length=500) object_type = models.ForeignKey(ContentType, on_delete=models.SET_NULL, null=True) fields = ArrayField(models.CharField(max_length=255), null=True) fields : contains an array of all the fields label of the DataType , this array is automatically generated upon creation. object_type : is a foreign key to the ContentType table that collects all the tables created by django. Therefore, it is a foreign key to a ContentType instance, thus, a table. Call backs post_delete_data() This callback function is called when a DataType instance is deleted, its purpose is to delete the related CustomDataType instance, thus deleting the DataType related table. FileExtention Class which instances represent what extension the file is using. Those extensions are used only by the app and are not necessary the standards extensions used by the different file systems. class FileExtention(models.Model): extention = models.CharField(max_length=20, unique=True) file_type = models.ForeignKey(FileType, on_delete=models.CASCADE, blank=False) def __str__(self): return self.extention FileChunk Class which instances represents individual files that constitute the ProjectFile . Those files are received by chunks and then regrouped to form a complete file who is then processed. class FileChunk(models.Model): to_project_files = models.ForeignKey(ProjectFile, on_delete=models.CASCADE, null=True, related_name='files') file = models.URLField(null=True, max_length=1200) file_name = models.CharField(max_length=500) nbr_chunk= models.IntegerField() cumulated_chunk = models.IntegerField() @property def allowed(self): return (self.to_project_files.project.user,) to_project_files : foreign key to the ProjectFile instance this file is related to. nbr_chunk : number of chunks expected to be received in the upload phase cumulated_chunk : number of chunks received and saved FileDataType Class which instances represents the files that are received in order to create a new DataType . class FileDataType(models.Model): to_data= models.ForeignKey(DataType, on_delete=models.CASCADE,null=True, related_name='files') file = models.FileField(upload_to=get_upload_to_data, #storage=StorageManager() # here we use the storage manager to rename the files if they exist ) Callbacks get_upload_to_data() function that returns the file path in which the file will be saved. CustomDataType This class stores the necessary data that will be used to create a model from a DataType , and the the corresponding table after migrating the model. class CustomDataType(models.Model): table_name = models.CharField(max_length=255) fields = models.JSONField() mapping = models.JSONField() params = models.JSONField() fields : fields of the DataType . They are stored in the following format { //\"field name\": \"field type\", \"nbr\": \"IntegerField\", \"name\": \"CharField\", } mapping : a json object that maps the table column to the corresponding field in the file used to extract the DataType fields { //\"field name in table\" : \"field name in file\", \"com\": \"COM\", \"f_id\": \"id\", \"geom\": \"POLYGON\", \"pv_module\": \"PV MODULE\", \"criticalit\": \"CRITICALIT\" } params : the django model parameters to include to the generated model fields on creation RasterData class that represents the data extracted from the raster files class RasterData(models.Model): project_file = models.ForeignKey(ProjectFile, on_delete=models.CASCADE, null=True) raster = models.ForeignKey(\"raster.RasterLayer\", on_delete=models.CASCADE, null=True) lon = models.FloatField() lat = models.FloatField() @property def allowed(self): return (self.project_file.project.user,) raster : foreign key to the RasterLayer instance related to the project_file ProjectField This class instances represent the area that contains the project on the map. It is extracted from the kml file uploaded on project creation. class ProjectField(models.Model): project = models.ForeignKey(Projects, on_delete=models.CASCADE, related_name='delimitation_field') geom = models.MultiPolygonField(srid=4326, dim=3) @property def allowed(self): if self.project: return (self.project_set.user,) return (None,) geom : A geometry field (based on GIS library) that contains the data extracted from the kml file.","title":"Models"},{"location":"Apps/files/MODELS/#models","text":"The files are handled by the App like files in a folder, the folder being the ProjectFile instance and the files in the folder are the files uploaded by the user saved as FileChunk instances. The FileChunk instance having a foreign key to the ProjectFile instance.","title":"Models"},{"location":"Apps/files/MODELS/#projectfile","text":"Class which instances represents the files uploaded by the AG_DATA users and that are meant to be seen and downloaded by CLIENT users, as well as visualized on the platform. class ProjectFile(models.Model): name = models.CharField(max_length=50, unique=True) description = models.CharField(max_length=500) file_type = models.ForeignKey(FileType, on_delete=models.CASCADE, null=True) file_extention = models.ForeignKey(FileExtention, on_delete=models.CASCADE, null=True) data_type = models.ForeignKey(DataType, on_delete=models.CASCADE, null=True) date = models.DateField(auto_now=True) project = models.ForeignKey(Projects, on_delete=models.CASCADE, null=True, related_name=\"to_project\") processed = models.BooleanField(default=False) error = models.BooleanField(default=False) error_message = models.CharField(max_length=500) def __str__(self): return self.name @property def allowed(self): return (self.project.user,) file_type : foreign key to FileType instance representing the file type (visualization mode) data_type : foreign key to DataType instance representing to what table the data should be extracted. project : foreign key to Project instance representing to what project the file is linked","title":"ProjectFile"},{"location":"Apps/files/MODELS/#callbacks","text":"","title":"CallBacks"},{"location":"Apps/files/MODELS/#post_delete_file","text":"This callback delete the related files from the Storage System thus freeing space by removing unused files.","title":"post_delete_file()"},{"location":"Apps/files/MODELS/#post_save_project_file","text":"This callback create a LayerOrder instance for the file if it is a GEO_FILE instance ( GEO_FILE is a FileType instance). It gives priority, putting them on top level, to files that has a data_type linked to them, thus files who are not rasters .","title":"post_save_Project_File()"},{"location":"Apps/files/MODELS/#layerorder","text":"These instances represents the layers dispositions on the map, GEO_FILE with higher order number are displayed over GEO_FILE with lower ones. class LayerOrder(models.Model): project_file = models.OneToOneField(ProjectFile, on_delete=models.CASCADE, primary_key=True) order = models.IntegerField(default=1)","title":"LayerOrder"},{"location":"Apps/files/MODELS/#filetype","text":"Each ProjectType instance has a FileType attribute that represent how the file should be visualized for example GEO_FILE will be visualized on maps, ANALYTICS in tables, IMAGES on pup ups etc.. You can check the Class Structure using this link : Link For Class Structure class FileType(models.Model): label = models.CharField(max_length=50, unique=True) description = models.CharField(max_length=500) def __str__(self): return self.label","title":"FileType"},{"location":"Apps/files/MODELS/#datatype","text":"Each ProjectType instance has a DataType attribute that represents how the file should be processed and where its data should be stored. In other words, it represents in what table the parsed data from the file will be stored, and what function will be used to parse de data You can check the Class Structure using this link : Link For Class Structure class DataType(models.Model): label = models.CharField(max_length=50, unique=True) description = models.CharField(max_length=500) object_type = models.ForeignKey(ContentType, on_delete=models.SET_NULL, null=True) fields = ArrayField(models.CharField(max_length=255), null=True) fields : contains an array of all the fields label of the DataType , this array is automatically generated upon creation. object_type : is a foreign key to the ContentType table that collects all the tables created by django. Therefore, it is a foreign key to a ContentType instance, thus, a table.","title":"DataType"},{"location":"Apps/files/MODELS/#call-backs","text":"","title":"Call backs"},{"location":"Apps/files/MODELS/#post_delete_data","text":"This callback function is called when a DataType instance is deleted, its purpose is to delete the related CustomDataType instance, thus deleting the DataType related table.","title":"post_delete_data()"},{"location":"Apps/files/MODELS/#fileextention","text":"Class which instances represent what extension the file is using. Those extensions are used only by the app and are not necessary the standards extensions used by the different file systems. class FileExtention(models.Model): extention = models.CharField(max_length=20, unique=True) file_type = models.ForeignKey(FileType, on_delete=models.CASCADE, blank=False) def __str__(self): return self.extention","title":"FileExtention"},{"location":"Apps/files/MODELS/#filechunk","text":"Class which instances represents individual files that constitute the ProjectFile . Those files are received by chunks and then regrouped to form a complete file who is then processed. class FileChunk(models.Model): to_project_files = models.ForeignKey(ProjectFile, on_delete=models.CASCADE, null=True, related_name='files') file = models.URLField(null=True, max_length=1200) file_name = models.CharField(max_length=500) nbr_chunk= models.IntegerField() cumulated_chunk = models.IntegerField() @property def allowed(self): return (self.to_project_files.project.user,) to_project_files : foreign key to the ProjectFile instance this file is related to. nbr_chunk : number of chunks expected to be received in the upload phase cumulated_chunk : number of chunks received and saved","title":"FileChunk"},{"location":"Apps/files/MODELS/#filedatatype","text":"Class which instances represents the files that are received in order to create a new DataType . class FileDataType(models.Model): to_data= models.ForeignKey(DataType, on_delete=models.CASCADE,null=True, related_name='files') file = models.FileField(upload_to=get_upload_to_data, #storage=StorageManager() # here we use the storage manager to rename the files if they exist )","title":"FileDataType"},{"location":"Apps/files/MODELS/#callbacks_1","text":"","title":"Callbacks"},{"location":"Apps/files/MODELS/#get_upload_to_data","text":"function that returns the file path in which the file will be saved.","title":"get_upload_to_data()"},{"location":"Apps/files/MODELS/#customdatatype","text":"This class stores the necessary data that will be used to create a model from a DataType , and the the corresponding table after migrating the model. class CustomDataType(models.Model): table_name = models.CharField(max_length=255) fields = models.JSONField() mapping = models.JSONField() params = models.JSONField() fields : fields of the DataType . They are stored in the following format { //\"field name\": \"field type\", \"nbr\": \"IntegerField\", \"name\": \"CharField\", } mapping : a json object that maps the table column to the corresponding field in the file used to extract the DataType fields { //\"field name in table\" : \"field name in file\", \"com\": \"COM\", \"f_id\": \"id\", \"geom\": \"POLYGON\", \"pv_module\": \"PV MODULE\", \"criticalit\": \"CRITICALIT\" } params : the django model parameters to include to the generated model fields on creation","title":"CustomDataType"},{"location":"Apps/files/MODELS/#rasterdata","text":"class that represents the data extracted from the raster files class RasterData(models.Model): project_file = models.ForeignKey(ProjectFile, on_delete=models.CASCADE, null=True) raster = models.ForeignKey(\"raster.RasterLayer\", on_delete=models.CASCADE, null=True) lon = models.FloatField() lat = models.FloatField() @property def allowed(self): return (self.project_file.project.user,) raster : foreign key to the RasterLayer instance related to the project_file","title":"RasterData"},{"location":"Apps/files/MODELS/#projectfield","text":"This class instances represent the area that contains the project on the map. It is extracted from the kml file uploaded on project creation. class ProjectField(models.Model): project = models.ForeignKey(Projects, on_delete=models.CASCADE, related_name='delimitation_field') geom = models.MultiPolygonField(srid=4326, dim=3) @property def allowed(self): if self.project: return (self.project_set.user,) return (None,) geom : A geometry field (based on GIS library) that contains the data extracted from the kml file.","title":"ProjectField"},{"location":"Apps/files/SERIALIZERS/","text":"Serializers FileChunkSerializer This is the Serializer that handles files uploaded by chunks. It first receive the first chunk and create the file instance using the create() function, then for every other chunk received it updates the instance using the update() function. create() This function receive the first chunk of the uploaded file and create an instance of the FileChunkSerializer that will represent the uploaded file. If the file has only one chunk, the file is directly created using that chunk and the file field is filled with the created file url. def create(self, validated_data): file = validated_data[\"chunk_file\"] chunk_index = validated_data[\"chunk_index\"] nbr_chunk = validated_data[\"nbr_chunk\"] fileName = validated_data[\"file_name\"] project_file = validated_data[\"to_project_files\"] # create the FileChunk instance file_obj = FileChunk.objects.create( cumulated_chunk = 1, nbr_chunk = nbr_chunk, file_name = fileName, to_project_files = project_file ) file_data = file.read() dir_name = project_file.project.name +'/'+ project_file.file_type.label +'/' +project_file.name + '/' +fileName.split('.')[0] file_id = f\"{fileName}_{chunk_index + 1}\" # create directory if not exist if not os.path.exists(f'buff/{dir_name}/tmp'): os.makedirs(f'buff/{dir_name}/tmp') temp_file_path = \"\" # if the file has only one chunk it creates the file directly if nbr_chunk == 1: temp_file_path = f'buff/{dir_name}/{fileName}' temp_google_path = f'projects/{project_file.project.proj_type.label}/{dir_name}/{fileName}' # else it create a temp file for the chunk received else: temp_file_path = f'buff/{dir_name}/tmp/{file_id}' temp_google_path = f'projects/{project_file.project.proj_type.label}/{dir_name}/tmp/{file_id}' # creating the file in google cloud storage and local storage with open(temp_file_path, 'wb') as temp_file: temp_file.write(file_data) with default_storage.open(temp_google_path,'wb') as google_temp_file: google_temp_file.write(file_data) if nbr_chunk == 1: # retrieve created file url if the file has only one chunk (the chunk created is the file itself) file_obj.file = default_storage.url(temp_google_path) file_obj.save() return file_obj update() this function receive the remaining chunks of an uploaded file, it the create a temperary file uing the chunk's data received. If all the file's chunks are received, this function proceed to group the chunks and create a final file from their data. It then fill the file field with the created file url. def update(self, instance, validated_data): file = validated_data[\"chunk_file\"] chunk_index = validated_data[\"chunk_index\"] # update number of chunks received instance.cumulated_chunk = instance.cumulated_chunk +1 file_id = f\"{instance.file_name}_{chunk_index + 1}\" # write the received chunk data to a temp file dir_name = instance.to_project_files.project.name +'/'+ instance.to_project_files.file_type.label + '/' +instance.to_project_files.name + '/' +instance.file_name.split('.')[0] temp_file_path = f'buff/{dir_name}/tmp/{file_id}' temp_google_path = f'projects/{instance.to_project_files.project.proj_type.label}/{dir_name}/tmp/{file_id}' # writing the chunks with open(temp_file_path, 'wb') as temp_file: temp_file.write(file.read()) with default_storage.open(temp_google_path, 'wb') as google_temp_file: google_temp_file.write(file.read()) # save the instance modifications instance.save() # if we received all the chunks for a file if instance.cumulated_chunk == instance.nbr_chunk: # create the combined/final file path final_file_path = f'buff/{dir_name}/{instance.file_name}' final_google_path = f'projects/{ instance.to_project_files.project.proj_type.label}/{dir_name}/{instance.file_name}' print(\"combining chunks\") # Combining chunks in local storage to form the final file with open(final_file_path, 'wb') as final_file: # reading all the chunks created for i in range(instance.nbr_chunk): chunk_file_path = f'buff/{dir_name}/tmp/{instance.file_name}_{i + 1}' print(f\"reading chunk {instance.file_name}_{i + 1}\") with open(chunk_file_path, 'rb') as chunk_file: # writing the chunk's data to the final file final_file.write(chunk_file.read()) print(\"combining chunks in default storage\") # Combining chunks in Cloud storage to form the final file with default_storage.open(final_google_path, 'wb') as google_final_file: # reading all the chunks created for i in range(instance.nbr_chunk): chunk_file_path = f'projects/{instance.to_project_files.project.proj_type.label}/{dir_name}/tmp/{instance.file_name}_{i + 1}' print(f\"reading chunk from default storage {instance.file_name}_{i + 1}\") # writing the chunk's data to the final file with default_storage.open(chunk_file_path, 'rb') as chunk_file: google_final_file.write(chunk_file.read()) # delete the chunk read default_storage.delete(chunk_file_path) # retrieve created file url instance.file = default_storage.url(final_google_path) instance.save() return instance ProjectFileChunkSerializer This serializer creates a ProjectFile instance, this instance is linked to multiple FileChunk therefor it should be created before adding the FileChunkSerializer instances DataTypeSerializer This serializer creates a DataType object, it needs either a xlsx file, a csv file or a collection of files forming a shapefile file. The data is then extracted form the files in order to extract the fields names and type and create a DataType and a model accordingly. create() This function uses an uploaded file and request parameters to create a DataType object accordingly, then a model is generated from the extracted data and then migrated and saved as a CustomDataType instance for future migration purposes, the model expression is also saved in the customModels.custom_models file. Functions used upload_raster() This function is used to extract a pyramid view from the raster file uploaded and save it as a RasterLayer object. see what pyramid view means raster_save_data_task() This function is a celery task used to process the uploaded raster file. It is run in background, and its job is to read the pixel matrix of raster file, and create the pyramid view from it saving the newly created matrixes to the database as RasterTile objects. create_color_map() This function is used to read a .SLD file and extract the color map from it creating a Legend object and assigning this object to the newly created RatsterLayer . upload_shapefile() This function collect the shapefile file uploaded and the DataType of the ProjectFile and then calls the de save_geo_data function to extract the file's data. upload_shapefile_images() This function collect the shapefile file uploaded and the DataType of the ProjectFile and then calls the de save_geo_data function to extract the file's data. It then retrieves the url for each picture uploaded with the shapefile and replace the corresponding path for the picture in the shapefile with the url retrieved. save_geo_data() This function extract the data from an shapefile file of a ProjectFile object and then save this data in the table related to the DataType of this object using the mapping object to map the attribute name of the shapefile to the column name of the table used. def save_geo_data(path, object_type, projectfile, verbose=True): this_path = os.path.join(Path(__file__).resolve().parent.parent / 'buff', path) # retrieving the custom model linked to the Contenttype instence of this projectfile model = apps.get_model(app_label=object_type.app_label, model_name=object_type.model) mapping = {} if model == TopoData: mapping = topoData_mapping elif model == IlotDeChalleurData: mapping = ilotDeChalleur_mapping else: mapping = CustomDataType.objects.get(table_name=object_type.model).mapping lm = CustomLayerMapping(model, this_path, mapping) lm.save(projectfile=projectfile,strict=True, verbose=False) upload_xlsx() This function collect the xlsx file uploaded and the DataType of the ProjectFile and then calls the de save_excel function to extract the file's data. save_excel() This function extract the data from an xlsx file of a ProjectFile object and then save this data in the table related to the DataType of this object def save_excel(path, object_type, projectfile): this_path = os.path.join(Path(__file__).resolve().parent.parent / 'buff', path) model = apps.get_model(app_label=object_type.app_label, model_name=object_type.model) excel_data_df = pandas.read_excel(this_path) new_dict = excel_data_df.to_dict('records') # objs= json.loads(json_str) for obj in new_dict: new_obj = {} for key in obj: new_obj[str(key).lower().strip().replace(\" \", \"_\")] = obj[key] test = model.objects.create(**new_obj) test.project_file = projectfile test.save() upload_csv() This function collect the csv file uploaded and the DataType of the ProjectFile and then call the de save_csv function to extract the file's data. save_csv() This function extract the data from an csv file of a ProjectFile object and then save this data in the table related to the DataType of this object def save_csv(path, object_type, projectfile): this_path = os.path.join(Path(__file__).resolve().parent.parent / 'buff', path) model = apps.get_model(app_label=object_type.app_label, model_name=object_type.model) excel_data_df = pandas.read_csv(this_path) new_dict = excel_data_df.to_dict('records') # objs= json.loads(json_str) for obj in new_dict: new_obj = {} for key in obj: key_name = str(key).lower().strip().replace(\" \", \"_\") if key_name[0] == \"\\\"\": key_name = key_name[1:] if key_name[-1] == \"\\\"\": key_name = key_name[:-1] new_obj[key_name] = obj[key] test = model.objects.create(**new_obj) test.project_file = projectfile test.save() create_datatype_shapefile() This function extracts the attributes from a shapefile and create a model from it saving it as a CustomDataType instance. create_datatype_csv() This function extracts the attributes from a file csv and create a model from it saving it as a CustomDataType instance. create_datatype_excel() This function extracts the attributes from an excel file and create a model from it saving it as a CustomDataType instance. create_model() This function uses a CustomDataType and returns a model from it. migrate_datatype() This function reads the CustomDataType object created, creates a model from it and saving the model expression (The model Class definition) in the customModels.custom_models file, then running a migration in order to migrate the model created and synchronize the table with the new DataType . This newly created model is available on runtime and is deleted on server restart, but writing the model expression in the customModels.custom_models keeps the model active even after restarting the server migrate_all() This function reads all the CustomDataType objects created, creates and saves the model expressions (The model Class definitions) in the customModels.custom_models file. This function is only used to sync the written models expressions in the customModels.custom_models with the CustomDataType objects available, and therefor its main purpose is to remove the deleted DataType objects from the customModels.custom_models file. The server must be restarted after the function call in order to take the customModels.custom_models changes into consideration. You can then run makemigrations and migrate after the server is restarted, or just call the /api/refresh-datatype/ api endpoint while de server is on, in order to sync the models with the database. !! warning If a model is not found in the customModels.custom_models file, it's table will be deleted on migrations and therefor all the data for this model ( DataType ) will be lost. Be careful when running a migration after editing this file.","title":"Serializers"},{"location":"Apps/files/SERIALIZERS/#serializers","text":"","title":"Serializers"},{"location":"Apps/files/SERIALIZERS/#filechunkserializer","text":"This is the Serializer that handles files uploaded by chunks. It first receive the first chunk and create the file instance using the create() function, then for every other chunk received it updates the instance using the update() function.","title":"FileChunkSerializer"},{"location":"Apps/files/SERIALIZERS/#create","text":"This function receive the first chunk of the uploaded file and create an instance of the FileChunkSerializer that will represent the uploaded file. If the file has only one chunk, the file is directly created using that chunk and the file field is filled with the created file url. def create(self, validated_data): file = validated_data[\"chunk_file\"] chunk_index = validated_data[\"chunk_index\"] nbr_chunk = validated_data[\"nbr_chunk\"] fileName = validated_data[\"file_name\"] project_file = validated_data[\"to_project_files\"] # create the FileChunk instance file_obj = FileChunk.objects.create( cumulated_chunk = 1, nbr_chunk = nbr_chunk, file_name = fileName, to_project_files = project_file ) file_data = file.read() dir_name = project_file.project.name +'/'+ project_file.file_type.label +'/' +project_file.name + '/' +fileName.split('.')[0] file_id = f\"{fileName}_{chunk_index + 1}\" # create directory if not exist if not os.path.exists(f'buff/{dir_name}/tmp'): os.makedirs(f'buff/{dir_name}/tmp') temp_file_path = \"\" # if the file has only one chunk it creates the file directly if nbr_chunk == 1: temp_file_path = f'buff/{dir_name}/{fileName}' temp_google_path = f'projects/{project_file.project.proj_type.label}/{dir_name}/{fileName}' # else it create a temp file for the chunk received else: temp_file_path = f'buff/{dir_name}/tmp/{file_id}' temp_google_path = f'projects/{project_file.project.proj_type.label}/{dir_name}/tmp/{file_id}' # creating the file in google cloud storage and local storage with open(temp_file_path, 'wb') as temp_file: temp_file.write(file_data) with default_storage.open(temp_google_path,'wb') as google_temp_file: google_temp_file.write(file_data) if nbr_chunk == 1: # retrieve created file url if the file has only one chunk (the chunk created is the file itself) file_obj.file = default_storage.url(temp_google_path) file_obj.save() return file_obj","title":"create()"},{"location":"Apps/files/SERIALIZERS/#update","text":"this function receive the remaining chunks of an uploaded file, it the create a temperary file uing the chunk's data received. If all the file's chunks are received, this function proceed to group the chunks and create a final file from their data. It then fill the file field with the created file url. def update(self, instance, validated_data): file = validated_data[\"chunk_file\"] chunk_index = validated_data[\"chunk_index\"] # update number of chunks received instance.cumulated_chunk = instance.cumulated_chunk +1 file_id = f\"{instance.file_name}_{chunk_index + 1}\" # write the received chunk data to a temp file dir_name = instance.to_project_files.project.name +'/'+ instance.to_project_files.file_type.label + '/' +instance.to_project_files.name + '/' +instance.file_name.split('.')[0] temp_file_path = f'buff/{dir_name}/tmp/{file_id}' temp_google_path = f'projects/{instance.to_project_files.project.proj_type.label}/{dir_name}/tmp/{file_id}' # writing the chunks with open(temp_file_path, 'wb') as temp_file: temp_file.write(file.read()) with default_storage.open(temp_google_path, 'wb') as google_temp_file: google_temp_file.write(file.read()) # save the instance modifications instance.save() # if we received all the chunks for a file if instance.cumulated_chunk == instance.nbr_chunk: # create the combined/final file path final_file_path = f'buff/{dir_name}/{instance.file_name}' final_google_path = f'projects/{ instance.to_project_files.project.proj_type.label}/{dir_name}/{instance.file_name}' print(\"combining chunks\") # Combining chunks in local storage to form the final file with open(final_file_path, 'wb') as final_file: # reading all the chunks created for i in range(instance.nbr_chunk): chunk_file_path = f'buff/{dir_name}/tmp/{instance.file_name}_{i + 1}' print(f\"reading chunk {instance.file_name}_{i + 1}\") with open(chunk_file_path, 'rb') as chunk_file: # writing the chunk's data to the final file final_file.write(chunk_file.read()) print(\"combining chunks in default storage\") # Combining chunks in Cloud storage to form the final file with default_storage.open(final_google_path, 'wb') as google_final_file: # reading all the chunks created for i in range(instance.nbr_chunk): chunk_file_path = f'projects/{instance.to_project_files.project.proj_type.label}/{dir_name}/tmp/{instance.file_name}_{i + 1}' print(f\"reading chunk from default storage {instance.file_name}_{i + 1}\") # writing the chunk's data to the final file with default_storage.open(chunk_file_path, 'rb') as chunk_file: google_final_file.write(chunk_file.read()) # delete the chunk read default_storage.delete(chunk_file_path) # retrieve created file url instance.file = default_storage.url(final_google_path) instance.save() return instance","title":"update()"},{"location":"Apps/files/SERIALIZERS/#projectfilechunkserializer","text":"This serializer creates a ProjectFile instance, this instance is linked to multiple FileChunk therefor it should be created before adding the FileChunkSerializer instances","title":"ProjectFileChunkSerializer"},{"location":"Apps/files/SERIALIZERS/#datatypeserializer","text":"This serializer creates a DataType object, it needs either a xlsx file, a csv file or a collection of files forming a shapefile file. The data is then extracted form the files in order to extract the fields names and type and create a DataType and a model accordingly.","title":"DataTypeSerializer"},{"location":"Apps/files/SERIALIZERS/#create_1","text":"This function uses an uploaded file and request parameters to create a DataType object accordingly, then a model is generated from the extracted data and then migrated and saved as a CustomDataType instance for future migration purposes, the model expression is also saved in the customModels.custom_models file.","title":"create()"},{"location":"Apps/files/SERIALIZERS/#functions-used","text":"","title":"Functions used"},{"location":"Apps/files/SERIALIZERS/#upload_raster","text":"This function is used to extract a pyramid view from the raster file uploaded and save it as a RasterLayer object. see what pyramid view means","title":"upload_raster()"},{"location":"Apps/files/SERIALIZERS/#raster_save_data_task","text":"This function is a celery task used to process the uploaded raster file. It is run in background, and its job is to read the pixel matrix of raster file, and create the pyramid view from it saving the newly created matrixes to the database as RasterTile objects.","title":"raster_save_data_task()"},{"location":"Apps/files/SERIALIZERS/#create_color_map","text":"This function is used to read a .SLD file and extract the color map from it creating a Legend object and assigning this object to the newly created RatsterLayer .","title":"create_color_map()"},{"location":"Apps/files/SERIALIZERS/#upload_shapefile","text":"This function collect the shapefile file uploaded and the DataType of the ProjectFile and then calls the de save_geo_data function to extract the file's data.","title":"upload_shapefile()"},{"location":"Apps/files/SERIALIZERS/#upload_shapefile_images","text":"This function collect the shapefile file uploaded and the DataType of the ProjectFile and then calls the de save_geo_data function to extract the file's data. It then retrieves the url for each picture uploaded with the shapefile and replace the corresponding path for the picture in the shapefile with the url retrieved.","title":"upload_shapefile_images()"},{"location":"Apps/files/SERIALIZERS/#save_geo_data","text":"This function extract the data from an shapefile file of a ProjectFile object and then save this data in the table related to the DataType of this object using the mapping object to map the attribute name of the shapefile to the column name of the table used. def save_geo_data(path, object_type, projectfile, verbose=True): this_path = os.path.join(Path(__file__).resolve().parent.parent / 'buff', path) # retrieving the custom model linked to the Contenttype instence of this projectfile model = apps.get_model(app_label=object_type.app_label, model_name=object_type.model) mapping = {} if model == TopoData: mapping = topoData_mapping elif model == IlotDeChalleurData: mapping = ilotDeChalleur_mapping else: mapping = CustomDataType.objects.get(table_name=object_type.model).mapping lm = CustomLayerMapping(model, this_path, mapping) lm.save(projectfile=projectfile,strict=True, verbose=False)","title":"save_geo_data()"},{"location":"Apps/files/SERIALIZERS/#upload_xlsx","text":"This function collect the xlsx file uploaded and the DataType of the ProjectFile and then calls the de save_excel function to extract the file's data.","title":"upload_xlsx()"},{"location":"Apps/files/SERIALIZERS/#save_excel","text":"This function extract the data from an xlsx file of a ProjectFile object and then save this data in the table related to the DataType of this object def save_excel(path, object_type, projectfile): this_path = os.path.join(Path(__file__).resolve().parent.parent / 'buff', path) model = apps.get_model(app_label=object_type.app_label, model_name=object_type.model) excel_data_df = pandas.read_excel(this_path) new_dict = excel_data_df.to_dict('records') # objs= json.loads(json_str) for obj in new_dict: new_obj = {} for key in obj: new_obj[str(key).lower().strip().replace(\" \", \"_\")] = obj[key] test = model.objects.create(**new_obj) test.project_file = projectfile test.save()","title":"save_excel()"},{"location":"Apps/files/SERIALIZERS/#upload_csv","text":"This function collect the csv file uploaded and the DataType of the ProjectFile and then call the de save_csv function to extract the file's data.","title":"upload_csv()"},{"location":"Apps/files/SERIALIZERS/#save_csv","text":"This function extract the data from an csv file of a ProjectFile object and then save this data in the table related to the DataType of this object def save_csv(path, object_type, projectfile): this_path = os.path.join(Path(__file__).resolve().parent.parent / 'buff', path) model = apps.get_model(app_label=object_type.app_label, model_name=object_type.model) excel_data_df = pandas.read_csv(this_path) new_dict = excel_data_df.to_dict('records') # objs= json.loads(json_str) for obj in new_dict: new_obj = {} for key in obj: key_name = str(key).lower().strip().replace(\" \", \"_\") if key_name[0] == \"\\\"\": key_name = key_name[1:] if key_name[-1] == \"\\\"\": key_name = key_name[:-1] new_obj[key_name] = obj[key] test = model.objects.create(**new_obj) test.project_file = projectfile test.save()","title":"save_csv()"},{"location":"Apps/files/SERIALIZERS/#create_datatype_shapefile","text":"This function extracts the attributes from a shapefile and create a model from it saving it as a CustomDataType instance.","title":"create_datatype_shapefile()"},{"location":"Apps/files/SERIALIZERS/#create_datatype_csv","text":"This function extracts the attributes from a file csv and create a model from it saving it as a CustomDataType instance.","title":"create_datatype_csv()"},{"location":"Apps/files/SERIALIZERS/#create_datatype_excel","text":"This function extracts the attributes from an excel file and create a model from it saving it as a CustomDataType instance.","title":"create_datatype_excel()"},{"location":"Apps/files/SERIALIZERS/#create_model","text":"This function uses a CustomDataType and returns a model from it.","title":"create_model()"},{"location":"Apps/files/SERIALIZERS/#migrate_datatype","text":"This function reads the CustomDataType object created, creates a model from it and saving the model expression (The model Class definition) in the customModels.custom_models file, then running a migration in order to migrate the model created and synchronize the table with the new DataType . This newly created model is available on runtime and is deleted on server restart, but writing the model expression in the customModels.custom_models keeps the model active even after restarting the server","title":"migrate_datatype()"},{"location":"Apps/files/SERIALIZERS/#migrate_all","text":"This function reads all the CustomDataType objects created, creates and saves the model expressions (The model Class definitions) in the customModels.custom_models file. This function is only used to sync the written models expressions in the customModels.custom_models with the CustomDataType objects available, and therefor its main purpose is to remove the deleted DataType objects from the customModels.custom_models file. The server must be restarted after the function call in order to take the customModels.custom_models changes into consideration. You can then run makemigrations and migrate after the server is restarted, or just call the /api/refresh-datatype/ api endpoint while de server is on, in order to sync the models with the database. !! warning If a model is not found in the customModels.custom_models file, it's table will be deleted on migrations and therefor all the data for this model ( DataType ) will be lost. Be careful when running a migration after editing this file.","title":"migrate_all()"},{"location":"Apps/files/VIEWS/","text":"","title":"VIEWS"},{"location":"Apps/hubspot_api/HUBSPOT_API/","text":"Hubspot Api App >> Go back to Home Menu << This is the Hubspot Api App Documentation ! 1. Models 2. Views 3. Serializers","title":"Hubspot Api App"},{"location":"Apps/hubspot_api/HUBSPOT_API/#hubspot-api-app","text":">> Go back to Home Menu << This is the Hubspot Api App Documentation !","title":"Hubspot Api App"},{"location":"Apps/hubspot_api/HUBSPOT_API/#1-models","text":"","title":"1. Models"},{"location":"Apps/hubspot_api/HUBSPOT_API/#2-views","text":"","title":"2. Views"},{"location":"Apps/hubspot_api/HUBSPOT_API/#3-serializers","text":"","title":"3. Serializers"},{"location":"Apps/hubspot_api/MODELS/","text":"","title":"MODELS"},{"location":"Apps/hubspot_api/SERIALIZERS/","text":"","title":"SERIALIZERS"},{"location":"Apps/hubspot_api/VIEWS/","text":"","title":"VIEWS"},{"location":"Apps/raster/MODELS/","text":"Models RasterLayer","title":"Models"},{"location":"Apps/raster/MODELS/#models","text":"","title":"Models"},{"location":"Apps/raster/MODELS/#rasterlayer","text":"","title":"RasterLayer"},{"location":"Apps/raster/RASTER/","text":"Raster App >> Go back to Home Menu << This is the Raster App Documentation ! 1. Models 2. Views 3. Serializers","title":"Raster App"},{"location":"Apps/raster/RASTER/#raster-app","text":">> Go back to Home Menu << This is the Raster App Documentation !","title":"Raster App"},{"location":"Apps/raster/RASTER/#1-models","text":"","title":"1. Models"},{"location":"Apps/raster/RASTER/#2-views","text":"","title":"2. Views"},{"location":"Apps/raster/RASTER/#3-serializers","text":"","title":"3. Serializers"},{"location":"Apps/raster/SERIALIZERS/","text":"","title":"SERIALIZERS"},{"location":"Apps/raster/VIEWS/","text":"","title":"VIEWS"},{"location":"Apps/reports/MODELS/","text":"","title":"MODELS"},{"location":"Apps/reports/REPORTS/","text":"Reports App >> Go back to Home Menu << This is the Reports App Documentation ! 1. Models 2. Views 3. Serializers","title":"Reports App"},{"location":"Apps/reports/REPORTS/#reports-app","text":">> Go back to Home Menu << This is the Reports App Documentation !","title":"Reports App"},{"location":"Apps/reports/REPORTS/#1-models","text":"","title":"1. Models"},{"location":"Apps/reports/REPORTS/#2-views","text":"","title":"2. Views"},{"location":"Apps/reports/REPORTS/#3-serializers","text":"","title":"3. Serializers"},{"location":"Apps/reports/SERIALIZERS/","text":"","title":"SERIALIZERS"},{"location":"Apps/reports/VIEWS/","text":"","title":"VIEWS"},{"location":"Apps/user/Models/","text":"Models Project","title":"Models"},{"location":"Apps/user/Models/#models","text":"","title":"Models"},{"location":"Apps/user/Models/#project","text":"","title":"Project"},{"location":"Apps/user/SERIALIZERS/","text":"","title":"SERIALIZERS"},{"location":"Apps/user/USER/","text":"USER App >> Go back to Home Menu << This is the USER App Documentation ! 1. Models 2. Views 3. Serializers","title":"USER App"},{"location":"Apps/user/USER/#user-app","text":">> Go back to Home Menu << This is the USER App Documentation !","title":"USER App"},{"location":"Apps/user/USER/#1-models","text":"","title":"1. Models"},{"location":"Apps/user/USER/#2-views","text":"","title":"2. Views"},{"location":"Apps/user/USER/#3-serializers","text":"","title":"3. Serializers"},{"location":"Apps/user/Views/","text":"User Views UserDetail","title":"User Views"},{"location":"Apps/user/Views/#user-views","text":"","title":"User Views"},{"location":"Apps/user/Views/#userdetail","text":"","title":"UserDetail"},{"location":"Architecture/Database/","text":"Database Architecture The database architecture can be probed via the graphs bellow: Note Click on the SVG image to browse the graph Note You can search the graph with the command CTRL + F","title":"Database"},{"location":"Architecture/Database/#database-architecture","text":"The database architecture can be probed via the graphs bellow: Note Click on the SVG image to browse the graph Note You can search the graph with the command CTRL + F","title":"Database Architecture"},{"location":"Architecture/Functionnal/","text":"","title":"Functionnal"},{"location":"installation/INSTALLATION/","text":"Installation Guide This is the Intheair Saas Platform installation guide, follow the guide to have the backend up and running on your environement. Note We suggest you to follow the installation to the end before running the server to avoid errors. Warning we suppose that you are in a docker or in a virtual environement, create one before following the installation if not ! Python dependencies All the django and python dependencies are added to the requirement.txt . To install the dependencies just run pip install -r <yourpath>/requirements.txt Geospatial dependencies After installing the python dependencies, we need to install some libraries and packages to use GDAL and GIS tools. First we need to run this command to install, directly or by dependency, the required geospatial libraries: sudo apt-get install cmake binutils libproj-dev gdal-bin Note It may be necessary to run the ldconfig command after installing each library. For example: shell sudo make install sudo ldconfig We will then have to install GEOS , a C++ library for performing geometric operations, and is the default internal geometry representation used by GeoDjango (it\u2019s behind the \u00ab lazy \u00bb geometries). Specifically, the C API library is called (e.g., libgeos_c.so) directly from Python using ctypes. First, download GEOS from the GEOS website and untar the source archive: wget https://download.osgeo.org/geos/geos-3.12.0.tar.bz2 tar xjf geos-3.12.0.tar.bz2 Then we have to build and install the package: cd geos-3.12.0 mkdir build cd build cmake -DCMAKE_BUILD_TYPE=Release .. cmake --build . sudo cmake --build . --target install Then we will have to install GDAL , First download the latest GDAL release version and untar the archive: wget https://download.osgeo.org/gdal/3.7.2/gdal-3.7.2.tar.gz tar xzf gdal-3.7.2.tar.gz Then we have to build and install the package: cd gdal-3.7.2 mkdir build cd build cmake .. cmake --build . sudo cmake --build . --target install Important If you get any errors while trying to install the GIS dependencies, try troubleshooting your environment via this link Geodjango Troubleshooting . RabbitMQ The backend uses celery in order to handle the async tasks, the celery library needs to connect to a messaging queue server in order to queue its tasks. To achieve that we need to install and run RabbitMQ a message queuing server and run it. For installing RabbitMQ on Linux just run this script and you are good to go: #!/bin/sh sudo apt-get install curl gnupg apt-transport-https -y ## Team RabbitMQ's main signing key curl -1sLf \"https://keys.openpgp.org/vks/v1/by-fingerprint/0A9AF2115F4687BD29803A206B73A36E6026DFCA\" | sudo gpg --dearmor | sudo tee /usr/share/keyrings/com.rabbitmq.team.gpg > /dev/null ## Community mirror of Cloudsmith: modern Erlang repository curl -1sLf https://github.com/rabbitmq/signing-keys/releases/download/3.0/cloudsmith.rabbitmq-erlang.E495BB49CC4BBE5B.key | sudo gpg --dearmor | sudo tee /usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg > /dev/null ## Community mirror of Cloudsmith: RabbitMQ repository curl -1sLf https://github.com/rabbitmq/signing-keys/releases/download/3.0/cloudsmith.rabbitmq-server.9F4587F226208342.key | sudo gpg --dearmor | sudo tee /usr/share/keyrings/rabbitmq.9F4587F226208342.gpg > /dev/null ## Add apt repositories maintained by Team RabbitMQ sudo tee /etc/apt/sources.list.d/rabbitmq.list <<EOF ## Provides modern Erlang/OTP releases ## deb [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main # another mirror for redundancy deb [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main ## Provides RabbitMQ ## deb [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main # another mirror for redundancy deb [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main EOF ## Update package indices sudo apt-get update -y ## Install Erlang packages sudo apt-get install -y erlang-base \\ erlang-asn1 erlang-crypto erlang-eldap erlang-ftp erlang-inets \\ erlang-mnesia erlang-os-mon erlang-parsetools erlang-public-key \\ erlang-runtime-tools erlang-snmp erlang-ssl \\ erlang-syntax-tools erlang-tftp erlang-tools erlang-xmerl ## Install rabbitmq-server and its dependencies sudo apt-get install rabbitmq-server -y --fix-missing Configuration To configure our environment please refer to the /intheair/.env file. Celery To use Celery we need to create a RabbitMQ user, a virtual host and allow that user access to that virtual host: sudo rabbitmqctl add_user <USER> <PASSWORD> sudo rabbitmqctl add_vhost <HOST NAME> sudo rabbitmqctl set_user_tags <USER> <TAG> sudo rabbitmqctl set_permissions -p <HOST NAME> <USER> \".*\" \".*\" \".*\" Substitute in appropriate values for myuser, mypassword and myvhost above. See the RabbitMQ access control documentation or the Admin Guide for more information. Email server The backend uses an emailing functionality, you can update the email section of the .env file to connect the backend to the smpt server used in the deployment EMAIL_HOST=<THE EMAIL SERVER HOST> EMAIL_PORT=<THE EMAIL SERVER PORT> EMAIL_HOST_USER=<THE EMAIL SERVER USER> EMAIL_HOST_PASSWORD=<THE EMAIL SERVER APP PASSWORD> CONTACT_EMAIL=<THE CONTACT EMAIL ADDRESS> DEFAULT_FROM_USER=<DEFAULT EXPEDITOR EMAIL (WILL PROBABLY BE THE CONTACT EMAIL ADDRESS)> Database The database used in our backend is a postgresql database, it needs to support GIS and raster functionalities. Make sure to install postgis and raster extensions in the database created (you can contact your database administrator to add the plugins). After creating and configuring the database you need to configure the backend to connect to it. Fill the variables in the .env file to allow the connection: DB_HOST=<DATABASE URL/HOST> DB_USERNAME=<USERNAME> DB_PASSWORD=<PASSWORD> DB_NAME=<DATABASE NAME> DB_PORT=<DATABASE PORT> Debug and Security For security purposes change the environment variables in the .env file to restrict/allow network access to the backend: # The generated DJANGO SECRET KEY SECRET_KEY=django-insecure-mt009#ax-n)0o@$=o31pg)e5$!xvx(^7cjdl(kf^6#yeo-tl)% # Set to True to have more details about the errors, or False when put to production DEBUG=False # the allowed DNS that have authorization to connect to the backend (it should be the Database DNS and Frontend DNS) ALLOWED_HOSTS=[<Front_DNS:PORT>, <DataBase_DNS:PORT>] # The allowed origins that can send form data to our backend (should be the Frontend DNS) ALLOWED_CRSF_ORIGINS=<Front_DNS:PORT> Run the server Init the Data Warning Don't run this section if you are using the always database pre-configured in this repository, only run it if you are using a new empty database ! To run the server we need to first migrate the data base: python manage.py makemigrations python manage.py migrate Then we have to create a super admin to manage the django admin section if needed, run this command and follow the instructions: python manage.py createsuperuser <USER> We then have to populate the data base with the required data. We first open a django shell: python manage.py shell Then we can use the built in script to create the data: from files import script as fs from user import script as us fs.add_data_type() us.init_data_base() 3 users have been created with this command: CLIENT type user : {email:client@gmail.com, password:intheair123} ADMIN type user : {email:admin@gmail.com, password:intheair123} AG_DATA type user : {email:data@gmail.com, password:intheair123} You can now exit the shell. Run To run the backend app you need to run the Django server , there RabbitMQ server and Celery . in the /intheair/ directory run this 3 commands in separate terminals: 1- Start Django server: python manage.py runserver --noreload 2- Start RabbitMQ: sudo rabbitmq-server start 3- Start Celery: celery -A intheair worker I hope the installation, configuration and running of the server went smoothly. Contact us if you ever have any problem or issue with the installation that the documentation didn't help you solve.","title":"Installation Guide"},{"location":"installation/INSTALLATION/#installation-guide","text":"This is the Intheair Saas Platform installation guide, follow the guide to have the backend up and running on your environement. Note We suggest you to follow the installation to the end before running the server to avoid errors. Warning we suppose that you are in a docker or in a virtual environement, create one before following the installation if not !","title":"Installation Guide"},{"location":"installation/INSTALLATION/#python-dependencies","text":"All the django and python dependencies are added to the requirement.txt . To install the dependencies just run pip install -r <yourpath>/requirements.txt","title":"Python dependencies"},{"location":"installation/INSTALLATION/#geospatial-dependencies","text":"After installing the python dependencies, we need to install some libraries and packages to use GDAL and GIS tools. First we need to run this command to install, directly or by dependency, the required geospatial libraries: sudo apt-get install cmake binutils libproj-dev gdal-bin Note It may be necessary to run the ldconfig command after installing each library. For example: shell sudo make install sudo ldconfig We will then have to install GEOS , a C++ library for performing geometric operations, and is the default internal geometry representation used by GeoDjango (it\u2019s behind the \u00ab lazy \u00bb geometries). Specifically, the C API library is called (e.g., libgeos_c.so) directly from Python using ctypes. First, download GEOS from the GEOS website and untar the source archive: wget https://download.osgeo.org/geos/geos-3.12.0.tar.bz2 tar xjf geos-3.12.0.tar.bz2 Then we have to build and install the package: cd geos-3.12.0 mkdir build cd build cmake -DCMAKE_BUILD_TYPE=Release .. cmake --build . sudo cmake --build . --target install Then we will have to install GDAL , First download the latest GDAL release version and untar the archive: wget https://download.osgeo.org/gdal/3.7.2/gdal-3.7.2.tar.gz tar xzf gdal-3.7.2.tar.gz Then we have to build and install the package: cd gdal-3.7.2 mkdir build cd build cmake .. cmake --build . sudo cmake --build . --target install Important If you get any errors while trying to install the GIS dependencies, try troubleshooting your environment via this link Geodjango Troubleshooting .","title":"Geospatial dependencies"},{"location":"installation/INSTALLATION/#rabbitmq","text":"The backend uses celery in order to handle the async tasks, the celery library needs to connect to a messaging queue server in order to queue its tasks. To achieve that we need to install and run RabbitMQ a message queuing server and run it. For installing RabbitMQ on Linux just run this script and you are good to go: #!/bin/sh sudo apt-get install curl gnupg apt-transport-https -y ## Team RabbitMQ's main signing key curl -1sLf \"https://keys.openpgp.org/vks/v1/by-fingerprint/0A9AF2115F4687BD29803A206B73A36E6026DFCA\" | sudo gpg --dearmor | sudo tee /usr/share/keyrings/com.rabbitmq.team.gpg > /dev/null ## Community mirror of Cloudsmith: modern Erlang repository curl -1sLf https://github.com/rabbitmq/signing-keys/releases/download/3.0/cloudsmith.rabbitmq-erlang.E495BB49CC4BBE5B.key | sudo gpg --dearmor | sudo tee /usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg > /dev/null ## Community mirror of Cloudsmith: RabbitMQ repository curl -1sLf https://github.com/rabbitmq/signing-keys/releases/download/3.0/cloudsmith.rabbitmq-server.9F4587F226208342.key | sudo gpg --dearmor | sudo tee /usr/share/keyrings/rabbitmq.9F4587F226208342.gpg > /dev/null ## Add apt repositories maintained by Team RabbitMQ sudo tee /etc/apt/sources.list.d/rabbitmq.list <<EOF ## Provides modern Erlang/OTP releases ## deb [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main # another mirror for redundancy deb [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.E495BB49CC4BBE5B.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-erlang/deb/ubuntu jammy main ## Provides RabbitMQ ## deb [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa1.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main # another mirror for redundancy deb [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main deb-src [signed-by=/usr/share/keyrings/rabbitmq.9F4587F226208342.gpg] https://ppa2.novemberain.com/rabbitmq/rabbitmq-server/deb/ubuntu jammy main EOF ## Update package indices sudo apt-get update -y ## Install Erlang packages sudo apt-get install -y erlang-base \\ erlang-asn1 erlang-crypto erlang-eldap erlang-ftp erlang-inets \\ erlang-mnesia erlang-os-mon erlang-parsetools erlang-public-key \\ erlang-runtime-tools erlang-snmp erlang-ssl \\ erlang-syntax-tools erlang-tftp erlang-tools erlang-xmerl ## Install rabbitmq-server and its dependencies sudo apt-get install rabbitmq-server -y --fix-missing","title":"RabbitMQ"},{"location":"installation/INSTALLATION/#configuration","text":"To configure our environment please refer to the /intheair/.env file.","title":"Configuration"},{"location":"installation/INSTALLATION/#celery","text":"To use Celery we need to create a RabbitMQ user, a virtual host and allow that user access to that virtual host: sudo rabbitmqctl add_user <USER> <PASSWORD> sudo rabbitmqctl add_vhost <HOST NAME> sudo rabbitmqctl set_user_tags <USER> <TAG> sudo rabbitmqctl set_permissions -p <HOST NAME> <USER> \".*\" \".*\" \".*\" Substitute in appropriate values for myuser, mypassword and myvhost above. See the RabbitMQ access control documentation or the Admin Guide for more information.","title":"Celery"},{"location":"installation/INSTALLATION/#email-server","text":"The backend uses an emailing functionality, you can update the email section of the .env file to connect the backend to the smpt server used in the deployment EMAIL_HOST=<THE EMAIL SERVER HOST> EMAIL_PORT=<THE EMAIL SERVER PORT> EMAIL_HOST_USER=<THE EMAIL SERVER USER> EMAIL_HOST_PASSWORD=<THE EMAIL SERVER APP PASSWORD> CONTACT_EMAIL=<THE CONTACT EMAIL ADDRESS> DEFAULT_FROM_USER=<DEFAULT EXPEDITOR EMAIL (WILL PROBABLY BE THE CONTACT EMAIL ADDRESS)>","title":"Email server"},{"location":"installation/INSTALLATION/#database","text":"The database used in our backend is a postgresql database, it needs to support GIS and raster functionalities. Make sure to install postgis and raster extensions in the database created (you can contact your database administrator to add the plugins). After creating and configuring the database you need to configure the backend to connect to it. Fill the variables in the .env file to allow the connection: DB_HOST=<DATABASE URL/HOST> DB_USERNAME=<USERNAME> DB_PASSWORD=<PASSWORD> DB_NAME=<DATABASE NAME> DB_PORT=<DATABASE PORT>","title":"Database"},{"location":"installation/INSTALLATION/#debug-and-security","text":"For security purposes change the environment variables in the .env file to restrict/allow network access to the backend: # The generated DJANGO SECRET KEY SECRET_KEY=django-insecure-mt009#ax-n)0o@$=o31pg)e5$!xvx(^7cjdl(kf^6#yeo-tl)% # Set to True to have more details about the errors, or False when put to production DEBUG=False # the allowed DNS that have authorization to connect to the backend (it should be the Database DNS and Frontend DNS) ALLOWED_HOSTS=[<Front_DNS:PORT>, <DataBase_DNS:PORT>] # The allowed origins that can send form data to our backend (should be the Frontend DNS) ALLOWED_CRSF_ORIGINS=<Front_DNS:PORT>","title":"Debug and Security"},{"location":"installation/INSTALLATION/#run-the-server","text":"","title":"Run the server"},{"location":"installation/INSTALLATION/#init-the-data","text":"Warning Don't run this section if you are using the always database pre-configured in this repository, only run it if you are using a new empty database ! To run the server we need to first migrate the data base: python manage.py makemigrations python manage.py migrate Then we have to create a super admin to manage the django admin section if needed, run this command and follow the instructions: python manage.py createsuperuser <USER> We then have to populate the data base with the required data. We first open a django shell: python manage.py shell Then we can use the built in script to create the data: from files import script as fs from user import script as us fs.add_data_type() us.init_data_base() 3 users have been created with this command: CLIENT type user : {email:client@gmail.com, password:intheair123} ADMIN type user : {email:admin@gmail.com, password:intheair123} AG_DATA type user : {email:data@gmail.com, password:intheair123} You can now exit the shell.","title":"Init the Data"},{"location":"installation/INSTALLATION/#run","text":"To run the backend app you need to run the Django server , there RabbitMQ server and Celery . in the /intheair/ directory run this 3 commands in separate terminals: 1- Start Django server: python manage.py runserver --noreload 2- Start RabbitMQ: sudo rabbitmq-server start 3- Start Celery: celery -A intheair worker I hope the installation, configuration and running of the server went smoothly. Contact us if you ever have any problem or issue with the installation that the documentation didn't help you solve.","title":"Run"}]}